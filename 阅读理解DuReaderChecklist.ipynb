{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "使用官方baseline：[https://aistudio.baidu.com/aistudio/projectdetail/1616829](https://aistudio.baidu.com/aistudio/projectdetail/1616829)\n",
    "\n",
    "该示例展示了如何使用PaddleNLP快速实现[LIC2021机器阅读理解比赛](https://aistudio.baidu.com/aistudio/competition/detail/66)基线并进阶优化基线。\n",
    "\n",
    "<br>\n",
    "\n",
    "机器阅读理解 (Machine Reading Comprehension) 是指让机器阅读文本，然后回答和阅读内容相关的问题。阅读理解是自然语言处理和人工智能领域的重要前沿课题，对于提升机器的智能水平、使机器具有持续知识获取的能力等具有重要价值，近年来受到学术界和工业界的广泛关注。\n",
    "\n",
    "自然语言理解对机器学习模型各方面的能力均有极高的要求。然而，当前的机器阅读理解数据集大多都只采用单一的指标来评测模型的好坏，缺乏对模型语言理解能力的细粒度、多维度评测，导致模型的具体缺陷很难被发现和改进。为了解决这个问题，中国计算机学会、中国中文信息学会和百度公司建立了细粒度的、多维度的评测数据集，从词汇理解、短语理解、语义角色理解、逻辑推理等多个维度检测模型的不足之处，从而推动阅读理解评测进入“精细化“时代。该数据集中的样本均来自于实际的应用场景，难度大，考察点丰富，覆盖了真实应用中诸多难以解决的问题。\n",
    "\n",
    "DuReader<sub>checklist</sub>数据集包含训练集、开发集以及测试集。其中开发集和测试集中，既包含和训练集同分布的in-domain样本，也包含了按照checklist体系分类后的样本。对于一个给定的问题q、一个篇章p及其标题t，系统需要根据篇章内容，判断该篇章p中是否包含给定问题的答案，如果是，则给出该问题的答案a；否则输出“no answer”。数据集中的每个样本，是一个四元组<q, p, t, a>，例如：\n",
    "\n",
    "* * *\n",
    "\n",
    "**问题 q**: 番石榴汁热量\n",
    "\n",
    "**篇章 p**: 番石榴性温,味甜、酸、涩…，最重要的是番石榴所含的脂肪热量较低,一个番石榴所含的脂肪约0.9克重或84卡路里。比起苹果,番石榴所含有的脂肪少38%,卡路里少42%。\n",
    "\n",
    "**标题 t**: 番石榴汁的热量 - 妈妈网百科\n",
    "\n",
    "\n",
    "**参考答案 a**: [‘一个番石榴所含的脂肪约0.9克重或84卡路里’]\n",
    "\n",
    "* * *\n",
    "\n",
    "**问题 q**: 云南文山市多少人口?\n",
    "\n",
    "**篇章 p**: 云南省下辖8个市、8个少数民族自治州,面积39万平方千米,总人口4596万人,云南汉族人口为3062.9万人,占云南省总人口的66.63%...\n",
    "\n",
    "**标题 t**: 云南总人口数多少人,2019年云南人口数量统计(最新)\n",
    "\n",
    "\n",
    "**参考答案 a**: [‘无答案’]\n",
    "\n",
    "* * *\n",
    "\n",
    "DuReader<sub>checklist</sub>数据集旨在通过建立checklist评测体系，系统性地评估当前模型能力的不足之处。目前checklist体系中涉及到的自然语言理解能力包含：词汇理解、短语理解、语义角色理解以及推理能力等等。具体的分类体系可参考下图：\n",
    "![checklist_framwork](https://ai-studio-static-online.cdn.bcebos.com/a27d5c7445884681b0d65be4eec1e6f3272aae1b4c534e178dfe2ec28a6ed302)\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "\n",
    "## 安装说明\n",
    "\n",
    "* PaddlePaddle 安装\n",
    "\n",
    "   本项目依赖于 PaddlePaddle 2.0 及以上版本，请参考 [安装指南](https://www.paddlepaddle.org.cn/install/quick?docurl=/documentation/docs/zh/install/pip/windows-pip.html) 进行安装\n",
    "\n",
    "* PaddleNLP 安装\n",
    "\n",
    "   ```shell\n",
    "   pip install --upgrade paddlenlp -i https://pypi.org/simple\n",
    "   ```\n",
    "\n",
    "* 环境依赖\n",
    "\n",
    "    Python的版本要求 3.6+\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "AI Studio平台后续会默认安装PaddleNLP，在此之前可使用如下命令安装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting paddlenlp\n",
      "\u001b[33m  WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))': /packages/62/10/ccc761d3e3a994703f31a4d0f93db0d13789d1c624a0cbbe9fe6439ed601/paddlenlp-2.0.5-py3-none-any.whl\u001b[0m\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/10/ccc761d3e3a994703f31a4d0f93db0d13789d1c624a0cbbe9fe6439ed601/paddlenlp-2.0.5-py3-none-any.whl (435kB)\n",
      "\u001b[K     |████████████████████████████████| 440kB 9.6kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: visualdl in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (2.2.0)\n",
      "Requirement already satisfied, skipping upgrade: h5py in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (2.9.0)\n",
      "Collecting multiprocess (from paddlenlp)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/aa/d8/d7bbcef5c03890f5fe983d8419b0c5236af3657c5aa9bddf1991a6ed813a/multiprocess-0.70.12.2-py37-none-any.whl (112kB)\n",
      "\u001b[K     |████████████████████████████████| 112kB 16kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: colorama in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (0.4.4)\n",
      "Requirement already satisfied, skipping upgrade: jieba in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (0.42.1)\n",
      "Requirement already satisfied, skipping upgrade: colorlog in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (4.1.0)\n",
      "Requirement already satisfied, skipping upgrade: seqeval in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (1.2.2)\n",
      "Requirement already satisfied, skipping upgrade: pre-commit in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (1.21.0)\n",
      "Requirement already satisfied, skipping upgrade: shellcheck-py in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (0.7.1.1)\n",
      "Requirement already satisfied, skipping upgrade: requests in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (2.22.0)\n",
      "Requirement already satisfied, skipping upgrade: Pillow>=7.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (7.1.2)\n",
      "Requirement already satisfied, skipping upgrade: pandas in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (1.1.5)\n",
      "Requirement already satisfied, skipping upgrade: Flask-Babel>=1.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (1.0.0)\n",
      "Requirement already satisfied, skipping upgrade: matplotlib in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (2.2.3)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.14.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (1.15.0)\n",
      "Requirement already satisfied, skipping upgrade: protobuf>=3.11.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (3.14.0)\n",
      "Requirement already satisfied, skipping upgrade: flask>=1.1.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (1.1.1)\n",
      "Requirement already satisfied, skipping upgrade: numpy in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (1.20.3)\n",
      "Requirement already satisfied, skipping upgrade: flake8>=3.7.9 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (3.8.2)\n",
      "Requirement already satisfied, skipping upgrade: bce-python-sdk in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (0.8.53)\n",
      "Collecting dill>=0.3.4 (from multiprocess->paddlenlp)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b6/c3/973676ceb86b60835bb3978c6db67a5dc06be6cfdbd14ef0f5a13e3fc9fd/dill-0.3.4-py2.py3-none-any.whl (86kB)\n",
      "\u001b[K     |████████████████████████████████| 92kB 9.6kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: scikit-learn>=0.21.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from seqeval->paddlenlp) (0.24.2)\n",
      "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl->paddlenlp) (0.23)\n",
      "Requirement already satisfied, skipping upgrade: pyyaml in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl->paddlenlp) (5.1.2)\n",
      "Requirement already satisfied, skipping upgrade: identify>=1.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl->paddlenlp) (1.4.10)\n",
      "Requirement already satisfied, skipping upgrade: toml in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl->paddlenlp) (0.10.0)\n",
      "Requirement already satisfied, skipping upgrade: virtualenv>=15.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl->paddlenlp) (16.7.9)\n",
      "Requirement already satisfied, skipping upgrade: nodeenv>=0.11.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl->paddlenlp) (1.3.4)\n",
      "Requirement already satisfied, skipping upgrade: cfgv>=2.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl->paddlenlp) (2.0.1)\n",
      "Requirement already satisfied, skipping upgrade: aspy.yaml in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl->paddlenlp) (1.3.0)\n",
      "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl->paddlenlp) (2.8)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl->paddlenlp) (1.25.6)\n",
      "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl->paddlenlp) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl->paddlenlp) (2019.9.11)\n",
      "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pandas->visualdl->paddlenlp) (2019.3)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.7.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pandas->visualdl->paddlenlp) (2.8.0)\n",
      "Requirement already satisfied, skipping upgrade: Babel>=2.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Flask-Babel>=1.0.0->visualdl->paddlenlp) (2.8.0)\n",
      "Requirement already satisfied, skipping upgrade: Jinja2>=2.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Flask-Babel>=1.0.0->visualdl->paddlenlp) (2.10.1)\n",
      "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->visualdl->paddlenlp) (2.4.2)\n",
      "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->visualdl->paddlenlp) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->visualdl->paddlenlp) (0.10.0)\n",
      "Requirement already satisfied, skipping upgrade: Werkzeug>=0.15 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl->paddlenlp) (0.16.0)\n",
      "Requirement already satisfied, skipping upgrade: itsdangerous>=0.24 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl->paddlenlp) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: click>=5.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl->paddlenlp) (7.0)\n",
      "Requirement already satisfied, skipping upgrade: pyflakes<2.3.0,>=2.2.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8>=3.7.9->visualdl->paddlenlp) (2.2.0)\n",
      "Requirement already satisfied, skipping upgrade: mccabe<0.7.0,>=0.6.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8>=3.7.9->visualdl->paddlenlp) (0.6.1)\n",
      "Requirement already satisfied, skipping upgrade: pycodestyle<2.7.0,>=2.6.0a1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8>=3.7.9->visualdl->paddlenlp) (2.6.0)\n",
      "Requirement already satisfied, skipping upgrade: pycryptodome>=3.8.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from bce-python-sdk->visualdl->paddlenlp) (3.9.9)\n",
      "Requirement already satisfied, skipping upgrade: future>=0.6.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from bce-python-sdk->visualdl->paddlenlp) (0.18.0)\n",
      "Requirement already satisfied, skipping upgrade: threadpoolctl>=2.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp) (2.1.0)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.19.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp) (1.6.3)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp) (0.14.1)\n",
      "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->pre-commit->visualdl->paddlenlp) (0.6.0)\n",
      "Requirement already satisfied, skipping upgrade: MarkupSafe>=0.23 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Jinja2>=2.5->Flask-Babel>=1.0.0->visualdl->paddlenlp) (1.1.1)\n",
      "Requirement already satisfied, skipping upgrade: setuptools in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib->visualdl->paddlenlp) (56.2.0)\n",
      "Requirement already satisfied, skipping upgrade: more-itertools in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from zipp>=0.5->importlib-metadata; python_version < \"3.8\"->pre-commit->visualdl->paddlenlp) (7.2.0)\n",
      "\u001b[31mERROR: blackhole 1.0.1 has requirement numpy<=1.19.5, but you'll have numpy 1.20.3 which is incompatible.\u001b[0m\n",
      "Installing collected packages: dill, multiprocess, paddlenlp\n",
      "  Found existing installation: dill 0.3.3\n",
      "    Uninstalling dill-0.3.3:\n",
      "      Successfully uninstalled dill-0.3.3\n",
      "  Found existing installation: paddlenlp 2.0.0rc7\n",
      "    Uninstalling paddlenlp-2.0.0rc7:\n",
      "      Successfully uninstalled paddlenlp-2.0.0rc7\n",
      "Successfully installed dill-0.3.4 multiprocess-0.70.12.2 paddlenlp-2.0.5\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade paddlenlp -i https://pypi.org/simple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 下载数据文件\n",
    "在运行基线之前，需要下载DuReader<sub>checklist</sub>数据集\n",
    "\n",
    "执行以下脚本，数据集会被保存到```dataset/```文件夹中。此外，基于[ERNIE-1.0](https://arxiv.org/abs/1904.09223)微调后的基线模型参数也会被保存在`finetuned_model/ `文件夹中，可供直接预测使用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download DuReader-checklist dataset\n",
      "--2021-07-16 11:04:39--  https://dataset-bj.cdn.bcebos.com/lic2021/dureader_checklist.dataset.tar.gz\n",
      "Resolving dataset-bj.cdn.bcebos.com (dataset-bj.cdn.bcebos.com)... 182.61.128.166\n",
      "Connecting to dataset-bj.cdn.bcebos.com (dataset-bj.cdn.bcebos.com)|182.61.128.166|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1636803 (1.6M) [application/x-gzip]\n",
      "Saving to: ‘dureader_checklist.dataset.tar.gz’\n",
      "\n",
      "dureader_checklist. 100%[===================>]   1.56M  --.-KB/s    in 0.02s   \n",
      "\n",
      "2021-07-16 11:04:39 (69.4 MB/s) - ‘dureader_checklist.dataset.tar.gz’ saved [1636803/1636803]\n",
      "\n",
      "dataset/\n",
      "dataset/dev.json\n",
      "dataset/train.json\n",
      "dataset/License.docx\n",
      "Download fine-tuned parameters\n",
      "--2021-07-16 11:04:39--  https://dataset-bj.cdn.bcebos.com/lic2021/dureader_checklist.finetuned_model.tar.gz\n",
      "Resolving dataset-bj.cdn.bcebos.com (dataset-bj.cdn.bcebos.com)... 182.61.128.166\n",
      "Connecting to dataset-bj.cdn.bcebos.com (dataset-bj.cdn.bcebos.com)|182.61.128.166|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 439315863 (419M) [application/x-gzip]\n",
      "Saving to: ‘dureader_checklist.finetuned_model.tar.gz’\n",
      "\n",
      "dureader_checklist. 100%[===================>] 418.96M  48.8MB/s    in 8.1s    \n",
      "\n",
      "2021-07-16 11:04:47 (51.9 MB/s) - ‘dureader_checklist.finetuned_model.tar.gz’ saved [439315863/439315863]\n",
      "\n",
      "finetuned_model/\n",
      "finetuned_model/tokenizer_config.json\n",
      "finetuned_model/model_state.pdparams\n",
      "finetuned_model/model_config.json\n",
      "finetuned_model/vocab.txt\n"
     ]
    }
   ],
   "source": [
    "#!sh download.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 数据准备\n",
    "\n",
    "数据准备流程如下：\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/89ba02da6f914297ae2fc438d1c9f773556f226652134fb684ac0186bfa5bb7d)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 使用`load_dataset()`自定义数据集\n",
    "\n",
    "DuReader<sub>checklist</sub>数据集采用SQuAD数据格式，我们可以写出数据文件读取函数，传入`load_dataset()`。即可创建数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "属鼠小名多米的寓意\n",
      "——使用叠字的小名是很好听的,对于刚刚出生的男孩来说,这样的名字是很方便记忆的,这也就拉近了孩子与家长之间的距离。糕,代表的是“用面粉所制成的食品”,那么此字在含义上是带有“多米”的含义,作为属鼠男孩的小名,寓意上是很不错的。\n",
      "['']\n",
      "[-1]\n",
      "True\n",
      "\n",
      "红烧肉煮鲍鱼的做法\n",
      "将锅中倒入油,小火爆香蒜末,一片姜的姜末,倒入上一步骤中蒸鲍鱼的汤汁,倒入蚝油,鲍鱼汁,蒸鱼豉油,东古一品鲜,味极鲜,糖,鸡精,鸡粉调味。如果汤汁少,放入少许水。待汤汁快要沸腾时,放入鲍鱼,均匀的裹上汤汁。最后,将鲍鱼放入已经摆盘的西兰花上面,将汤汁淋到鲍鱼上面就大功告成啦🤓\n",
      "['']\n",
      "[-1]\n",
      "True\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from paddlenlp.datasets import load_dataset\r\n",
    "import json\r\n",
    "\r\n",
    "# 根据本地文件格式定义数据读取生成器\r\n",
    "def read(filename):\r\n",
    "    with open(filename, \"r\", encoding=\"utf8\") as f:\r\n",
    "        input_data = json.load(f)\r\n",
    "        for entry in input_data['data']:\r\n",
    "            title = entry.get(\"title\", \"\").strip()\r\n",
    "            for paragraph in entry[\"paragraphs\"]:\r\n",
    "                context = paragraph[\"context\"].strip()\r\n",
    "                for qa in paragraph[\"qas\"]:\r\n",
    "                    qas_id = qa[\"id\"]\r\n",
    "                    question = qa[\"question\"].strip()\r\n",
    "                    answer_starts = []\r\n",
    "                    answers = []\r\n",
    "                    is_impossible = False\r\n",
    "\r\n",
    "                    if \"is_impossible\" in qa.keys():\r\n",
    "                        is_impossible = qa[\"is_impossible\"]\r\n",
    "\r\n",
    "                    answer_starts = [\r\n",
    "                        answer[\"answer_start\"] for answer in qa.get(\"answers\",[])\r\n",
    "                    ]\r\n",
    "                    answers = [\r\n",
    "                        answer[\"text\"].strip() for answer in qa.get(\"answers\",[])\r\n",
    "                    ]\r\n",
    "\r\n",
    "                    yield {\r\n",
    "                        'id': qas_id,\r\n",
    "                        'title': title,\r\n",
    "                        'context': context,\r\n",
    "                        'question': question,\r\n",
    "                        'answers': answers,\r\n",
    "                        'answer_starts': answer_starts,\r\n",
    "                        'is_impossible': is_impossible\r\n",
    "                    }\r\n",
    "\r\n",
    "# 将生成器传入load_dataset\r\n",
    "train_ds = load_dataset(read, filename='dataset/train.json', lazy=False)\r\n",
    "dev_ds = load_dataset(read, filename='dataset/dev.json', lazy=False)\r\n",
    "\r\n",
    "for idx in range(2):\r\n",
    "    print(train_ds[idx]['question'])\r\n",
    "    print(train_ds[idx]['context'])\r\n",
    "    print(train_ds[idx]['answers'])\r\n",
    "    print(train_ds[idx]['answer_starts'])\r\n",
    "    print(train_ds[idx]['is_impossible'])\r\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "关于更多自定义数据集相关内容，请移步[如何自定义数据集](https://paddlenlp.readthedocs.io/en/latest/data_prepare/dataset_self_defined.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 使用 `paddlenlp.transformers.ErnieTokenizer`将数据转为Feature\n",
    "\n",
    "DuReader<sub>checklist</sub>数据集采用SQuAD数据格式，InputFeature使用滑动窗口的方法生成，即一个example可能对应多个InputFeature。\n",
    "\n",
    "由于文章加问题的文本长度可能大于max_seq_length，答案出现的位置有可能出现在文章最后，所以不能简单的对文章进行截断。\n",
    "\n",
    "那么对于过长的文章，则采用滑动窗口将文章分成多段，分别与问题组合。再用对应的tokenizer转化为模型可接受的feature。doc_stride参数就是每次滑动的距离。滑动窗口生成InputFeature的过程如下图：\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/5776cf9ec00546bca047a0930c8f56a8b64d723e0ff04f269334522954bb7d90)\n",
    "\n",
    "本基线中，我们使用的预训练模型是ERNIE，ERNIE对中文数据的处理是以字为单位。**PaddleNLP对于各种预训练模型已经内置了相应的tokenizer**，指定想要使用的模型名字即可加载对应的tokenizer。\n",
    "\n",
    "tokenizer的作用是将原始输入文本转化成模型可以接受的输入数据形式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-07-16 11:27:42,405] [    INFO] - Found /home/aistudio/.paddlenlp/models/ernie-1.0/vocab.txt\n"
     ]
    }
   ],
   "source": [
    "import paddlenlp\r\n",
    "\r\n",
    "# 设置模型名称\r\n",
    "MODEL_NAME = 'ernie-1.0'\r\n",
    "tokenizer = paddlenlp.transformers.ErnieTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 调用`map()`方法批量处理数据\n",
    "\n",
    "由于我们传入了`lazy=False`，所以我们使用`load_dataset()`自定义的数据集是`MapDataset`对象，`MapDataset`是`paddle.io.Dataset`的功能增强版本。其内置的`map()`方法适合用来进行批量数据集处理。`map()`方法传入的是一个用于数据处理的function。正好可以与tokenizer相配合。\n",
    "\n",
    "以下是本基线中的用法："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from src.utils import prepare_train_features, prepare_validation_features\r\n",
    "from functools import partial\r\n",
    "\r\n",
    "max_seq_length = 512\r\n",
    "doc_stride = 128\r\n",
    "\r\n",
    "train_trans_func = partial(prepare_train_features, \r\n",
    "                           max_seq_length=max_seq_length, \r\n",
    "                           doc_stride=doc_stride,\r\n",
    "                           tokenizer=tokenizer)\r\n",
    "\r\n",
    "train_ds.map(train_trans_func, batched=True)\r\n",
    "\r\n",
    "dev_trans_func = partial(prepare_validation_features, \r\n",
    "                           max_seq_length=max_seq_length, \r\n",
    "                           doc_stride=doc_stride,\r\n",
    "                           tokenizer=tokenizer)\r\n",
    "                           \r\n",
    "dev_ds.map(dev_trans_func, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for idx in range(2):\r\n",
    "    print(train_ds[idx]['input_ids'])\r\n",
    "    print(train_ds[idx]['token_type_ids'])\r\n",
    "    print(train_ds[idx]['overflow_to_sample'])\r\n",
    "    print(train_ds[idx]['offset_mapping'])\r\n",
    "    print(train_ds[idx]['start_positions'])\r\n",
    "    print(train_ds[idx]['end_positions'])\r\n",
    "    print(train_ds[idx]['answerable_label'])\r\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "从以上结果可以看出，数据集中的example已经被转换成了模型可以接收的feature，包括input_ids、token_type_ids、答案的起始位置等信息。\n",
    "其中：\n",
    "\n",
    "* `input_ids`: 表示输入文本的token ID。\n",
    "* `token_type_ids`: 表示对应的token属于输入的问题还是答案。（Transformer类预训练模型支持单句以及句对输入）。\n",
    "* `overflow_to_sample`: feature对应的example的编号。\n",
    "* `offset_mapping`: 每个token的起始字符和结束字符在原文中对应的index（用于生成答案文本）。\n",
    "* `start_positions`: 答案在这个feature中的开始位置。\n",
    "* `end_positions`: 答案在这个feature中的结束位置。\n",
    "* `answerable_label`: 答案在这个feature中是否存在，存在为1，不存在为0。\n",
    "\n",
    "关于本基线中数据处理的详细过程请参见`src/utils.py`。\n",
    "\n",
    "更多有关数据处理的内容，请移步[数据处理](https://paddlenlp.readthedocs.io/en/latest/data_prepare/data_preprocess.html)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Batchify和数据读入\n",
    "\n",
    "使用`paddle.io.BatchSampler`和`paddlenlp.data`中提供的方法把数据组成batch。\n",
    "\n",
    "然后使用`paddle.io.DataLoader`接口多线程异步加载数据。\n",
    "\n",
    "`batchify_fn`详解：\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/30e43d4659384375a2a2c1b890ca5a995c4324d7168e49cebf1d2a1e99161f7d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import paddle\r\n",
    "from paddlenlp.data import Stack, Dict, Pad\r\n",
    "\r\n",
    "batch_size = 2\r\n",
    "\r\n",
    "# 初始化BatchSampler\r\n",
    "train_batch_sampler = paddle.io.BatchSampler(\r\n",
    "    train_ds, batch_size=batch_size, shuffle=True)\r\n",
    "\r\n",
    "dev_batch_sampler = paddle.io.BatchSampler(\r\n",
    "    dev_ds, batch_size=batch_size, shuffle=False)\r\n",
    "\r\n",
    "# 定义batchify_fn\r\n",
    "train_batchify_fn = lambda samples, fn=Dict({\r\n",
    "    \"input_ids\": Pad(axis=0, pad_val=tokenizer.pad_token_id), \r\n",
    "    \"token_type_ids\": Pad(axis=0, pad_val=tokenizer.pad_token_type_id),\r\n",
    "    \"start_positions\": Stack(dtype=\"int64\"),  \r\n",
    "    \"end_positions\": Stack(dtype=\"int64\"),  \r\n",
    "    \"answerable_label\": Stack(dtype=\"int64\")  \r\n",
    "}): fn(samples)\r\n",
    "\r\n",
    "dev_batchify_fn = lambda samples, fn=Dict({\r\n",
    "    \"input_ids\": Pad(axis=0, pad_val=tokenizer.pad_token_id), \r\n",
    "    \"token_type_ids\": Pad(axis=0, pad_val=tokenizer.pad_token_type_id)\r\n",
    "}): fn(samples)\r\n",
    "\r\n",
    "# 初始化DataLoader\r\n",
    "train_data_loader = paddle.io.DataLoader(\r\n",
    "    dataset=train_ds,\r\n",
    "    batch_sampler=train_batch_sampler,\r\n",
    "    collate_fn=train_batchify_fn,\r\n",
    "    return_list=True)\r\n",
    "\r\n",
    "dev_data_loader = paddle.io.DataLoader(\r\n",
    "    dataset=dev_ds,\r\n",
    "    batch_sampler=dev_batch_sampler,\r\n",
    "    collate_fn=dev_batchify_fn,\r\n",
    "    return_list=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 组网训练\n",
    "\n",
    "## 使用PaddleNLP一键加载预训练模型\n",
    "\n",
    "以下项目以ERNIE为例，介绍如何将预训练模型Fine-tune完成DuReader<sub>checklist</sub>阅读理解任务。\n",
    "\n",
    "DuReader<sub>checklist</sub>阅读理解任务的本质是答案抽取任务和句对分类任务。根据输入的问题和文章，预测答案在文章中的起始位置和结束位置以及判断答案是否存在。原理如下图所示：\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/1592580788c54e7b9b2491862836962c4163fe66c8bc44aabada0cf89f56f0e7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from src.models import ErnieForQuestionAnswering\n",
    "\n",
    "model = ErnieForQuestionAnswering.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 设计loss function\n",
    "\n",
    "ErineForQuestionAnswering模型对将BertModel的sequence_output拆开成start_logits和end_logits输出，并将pooled_output作为cls_logits输出，所以DuReader<sub>checklist</sub>的loss由start_loss和end_loss和cls_logits三部分组成，我们需要自己定义loss function。\n",
    "\n",
    "对于答案起始位置和结束位置和答案是否存在的预测可以分别看成三个分类任务。所以设计的loss function如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class CrossEntropyLossForChecklist(paddle.nn.Layer):\r\n",
    "    def __init__(self):\r\n",
    "        super(CrossEntropyLossForChecklist, self).__init__()\r\n",
    "        \r\n",
    "    def forward(self, y, label):\r\n",
    "        start_logits, end_logits, cls_logits = y\r\n",
    "        start_position, end_position, answerable_label = label\r\n",
    "        start_position = paddle.unsqueeze(start_position, axis=-1)\r\n",
    "        end_position = paddle.unsqueeze(end_position, axis=-1)\r\n",
    "        answerable_label = paddle.unsqueeze(answerable_label, axis=-1)\r\n",
    "        start_loss = paddle.nn.functional.softmax_with_cross_entropy(\r\n",
    "            logits=start_logits, label=start_position, soft_label=False)\r\n",
    "        start_loss = paddle.mean(start_loss)\r\n",
    "        end_loss = paddle.nn.functional.softmax_with_cross_entropy(\r\n",
    "            logits=end_logits, label=end_position, soft_label=False)\r\n",
    "        end_loss = paddle.mean(end_loss)\r\n",
    "        cls_loss = paddle.nn.functional.softmax_with_cross_entropy(\r\n",
    "            logits=cls_logits, label=answerable_label, soft_label=False)\r\n",
    "        cls_loss = paddle.mean(cls_loss)\r\n",
    "        mrc_loss = (start_loss + end_loss) / 2\r\n",
    "        loss = (mrc_loss + cls_loss) /2\r\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 模型配置\n",
    "\n",
    "### 配置优化策略\n",
    "适用于ERNIE/BERT这类Transformer模型的学习率为warmup的动态学习率。\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"https://ai-studio-static-online.cdn.bcebos.com/2bc624280a614a80b5449773192be460f195b13af89e4e5cbaf62bf6ac16de2c\" width=\"40%\" height=\"30%\"/> <br />\n",
    "</p>\n",
    "<br><center>图3：动态学习率示意图</center></br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 训练过程中的最大学习率\r\n",
    "learning_rate = 3e-5 \r\n",
    "\r\n",
    "# 训练轮次\r\n",
    "epochs = 2\r\n",
    "\r\n",
    "# 学习率预热比例\r\n",
    "warmup_proportion = 0.1\r\n",
    "\r\n",
    "# 权重衰减系数，类似模型正则项策略，避免模型过拟合\r\n",
    "weight_decay = 0.01\r\n",
    "\r\n",
    "num_training_steps = len(train_data_loader) * epochs\r\n",
    "\r\n",
    "# 学习率衰减策略\r\n",
    "lr_scheduler = paddlenlp.transformers.LinearDecayWithWarmup(learning_rate, num_training_steps,\r\n",
    "                                    warmup_proportion)\r\n",
    "\r\n",
    "decay_params = [\r\n",
    "    p.name for n, p in model.named_parameters()\r\n",
    "    if not any(nd in n for nd in [\"bias\", \"norm\"])\r\n",
    "]\r\n",
    "\r\n",
    "# 定义优化器\r\n",
    "optimizer = paddle.optimizer.AdamW(\r\n",
    "    learning_rate=lr_scheduler,\r\n",
    "    parameters=model.parameters(),\r\n",
    "    weight_decay=weight_decay,\r\n",
    "    apply_decay_param_fun=lambda x: x in decay_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 模型训练\n",
    "\n",
    "模型训练的过程通常有以下步骤：\n",
    "\n",
    "1. 从dataloader中取出一个batch data\n",
    "2. 将batch data喂给model，做前向计算\n",
    "3. 将前向计算结果传给损失函数，计算loss。\n",
    "4. loss反向回传，更新梯度。重复以上步骤。\n",
    "\n",
    "每训练一个epoch后，程序通过evaluate()调用`compute_prediction_checklist()`生成可提交的答案。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from src.utils import evaluate\r\n",
    "\r\n",
    "criterion = CrossEntropyLossForChecklist()\r\n",
    "global_step = 0\r\n",
    "for epoch in range(1, epochs + 1):\r\n",
    "    for step, batch in enumerate(train_data_loader, start=1):\r\n",
    "        \r\n",
    "        global_step += 1\r\n",
    "        input_ids, token_type_ids, start_positions, end_positions, answerable_label = batch\r\n",
    "        logits = model(input_ids=input_ids, token_type_ids=token_type_ids)\r\n",
    "        loss = criterion(logits, (start_positions, end_positions,answerable_label))\r\n",
    "\r\n",
    "        if global_step % 100 == 0 :\r\n",
    "            print(\"global step %d, epoch: %d, batch: %d, loss: %.5f\" % (global_step, epoch, step, loss))\r\n",
    "            \r\n",
    "        loss.backward()\r\n",
    "        optimizer.step()\r\n",
    "        lr_scheduler.step()\r\n",
    "        optimizer.clear_grad()\r\n",
    "\r\n",
    "evaluate(model, dev_data_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 模型评估\n",
    "\n",
    "本次评测所采用的评价指标为F1-score和Exact Match (EM)。其中F1作为主要评价指标，EM作为辅助评价指标。\n",
    "\n",
    "评估脚本的运行参考以下命令:\n",
    "\n",
    "```\n",
    "sh run_eval.sh dataset_file pred_file\n",
    "```\n",
    "\n",
    "其中`dataset_file `是数据集文件，`pred_file`是模型预测结果，例如\n",
    "\n",
    "```\n",
    "sh run_eval.sh dataset/dev.json prediction.json\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!sh run_eval.sh dataset/dev.json prediction.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 如何提升结果\n",
    "\n",
    "## 数据增强\n",
    "\n",
    "PaddleNLP内置的Dureader-robust数据集与该比赛的数据集格式相似。可以通过PaddleNLP内置的`load_dataset()`方法一键加载数据集用于数据集增强（需要进行一些处理保证格式一致）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from paddlenlp.datasets import load_dataset\r\n",
    "\r\n",
    "train_robust, dev_robust = load_dataset('dureader_robust',splits=('train','dev'))\r\n",
    "\r\n",
    "for idx in range(2):\r\n",
    "    print(train_robust[idx]['question'])\r\n",
    "    print(train_robust[idx]['context'])\r\n",
    "    print(train_robust[idx]['answers'])\r\n",
    "    print(train_robust[idx]['answer_starts'])\r\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 使用更大的模型\n",
    "\n",
    "PaddleNLP不仅支持ERNIE预训练模型，还支持BERT、RoBERTa等预训练模型，加载方式都与ERNIE的加载方式相同。\n",
    "使用更大的模型（例如`roberta-wwm-ext-large`）通常可以获得更好的效果。\n",
    "\n",
    "更多预训练模型参考：[https://github.com/PaddlePaddle/PaddleNLP/blob/develop/docs/transformers.md](https://github.com/PaddlePaddle/PaddleNLP/blob/develop/docs/transformers.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 对抗训练\n",
    "\n",
    "通过在词向量中添加干扰词向量来生成干扰样本。\n",
    "\n",
    "重新训练模型，以增强模型的鲁棒性。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 知识蒸馏，模型融合等"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "以上基线实现基于PaddleNLP，开源不易，希望大家多多支持~ \n",
    "**记得给[PaddleNLP](https://github.com/PaddlePaddle/PaddleNLP)点个小小的Star⭐**\n",
    "\n",
    "GitHub地址：[https://github.com/PaddlePaddle/PaddleNLP](https://github.com/PaddlePaddle/PaddleNLP)\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/a0e8ca7743ea4fe9aa741682a63e767f8c48dc55981f4e44a40e0e00d3ab369e)\n",
    "\n",
    "**更多使用方法可参考PaddleNLP教程**\n",
    "\n",
    "- [使用seq2vec模块进行句子情感分类](https://aistudio.baidu.com/aistudio/projectdetail/1283423)\n",
    "- [使用预训练模型ERNIE优化情感分析](https://aistudio.baidu.com/aistudio/projectdetail/1294333)\n",
    "- [使用BiGRU-CRF模型完成快递单信息抽取](https://aistudio.baidu.com/aistudio/projectdetail/1317771)\n",
    "- [使用预训练模型ERNIE优化快递单信息抽取](https://aistudio.baidu.com/aistudio/projectdetail/1329361)\n",
    "- [使用Seq2Seq模型完成自动对联](https://aistudio.baidu.com/aistudio/projectdetail/1321118)\n",
    "- [使用预训练模型ERNIE-GEN自动写诗](https://aistudio.baidu.com/aistudio/projectdetail/1339888)\n",
    "- [使用TCN网络完成新冠疫情病例数预测](https://aistudio.baidu.com/aistudio/projectdetail/1290873)\n",
    "- [自定义数据集实现文本多分类任务](https://aistudio.baidu.com/aistudio/projectdetail/1468469)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 加入交流群，一起学习吧\n",
    "\n",
    "现在就加入PaddleNLP的QQ技术交流群，一起交流NLP技术吧！\n",
    "\n",
    "<img src=\"https://ai-studio-static-online.cdn.bcebos.com/d953727af0c24a7c806ab529495f0904f22f809961be420b8c88cdf59b837394\" width=\"200\" height=\"250\" >"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 2.0.0b0 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
