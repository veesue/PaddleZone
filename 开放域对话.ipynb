{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 2021语言与智能技术竞赛：多技能对话\n",
    "\n",
    "多技能对话系统旨在建立一个开放域的多轮对话系统，能自然地融合多个对话技能，比如知识对话、推荐对话等，使得机器可以流畅自然地与人进行语言交互，从而有效地提升用户体验。\n",
    "\n",
    "该示例展示了如何使用PaddleNLP快速搭建[2021语言与智能技术竞赛：多技能对话](https://aistudio.baidu.com/aistudio/competition/detail/67)基线并进阶优化基线。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: paddlenlp in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (2.0.5)\n",
      "Requirement already satisfied, skipping upgrade: visualdl in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (2.2.0)\n",
      "Requirement already satisfied, skipping upgrade: colorlog in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (4.1.0)\n",
      "Requirement already satisfied, skipping upgrade: h5py in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (2.9.0)\n",
      "Requirement already satisfied, skipping upgrade: seqeval in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (1.2.2)\n",
      "Requirement already satisfied, skipping upgrade: jieba in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (0.42.1)\n",
      "Requirement already satisfied, skipping upgrade: multiprocess in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (0.70.12.2)\n",
      "Requirement already satisfied, skipping upgrade: colorama in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (0.4.4)\n",
      "Requirement already satisfied, skipping upgrade: flask>=1.1.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (1.1.1)\n",
      "Requirement already satisfied, skipping upgrade: protobuf>=3.11.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (3.14.0)\n",
      "Requirement already satisfied, skipping upgrade: Flask-Babel>=1.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (1.0.0)\n",
      "Requirement already satisfied, skipping upgrade: flake8>=3.7.9 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (3.8.2)\n",
      "Requirement already satisfied, skipping upgrade: requests in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (2.22.0)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.14.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (1.15.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (1.20.3)\n",
      "Requirement already satisfied, skipping upgrade: matplotlib in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (2.2.3)\n",
      "Requirement already satisfied, skipping upgrade: bce-python-sdk in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (0.8.53)\n",
      "Requirement already satisfied, skipping upgrade: Pillow>=7.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (7.1.2)\n",
      "Requirement already satisfied, skipping upgrade: pandas in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (1.1.5)\n",
      "Requirement already satisfied, skipping upgrade: pre-commit in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (1.21.0)\n",
      "Requirement already satisfied, skipping upgrade: shellcheck-py in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (0.7.1.1)\n",
      "Requirement already satisfied, skipping upgrade: scikit-learn>=0.21.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from seqeval->paddlenlp) (0.24.2)\n",
      "Requirement already satisfied, skipping upgrade: dill>=0.3.4 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from multiprocess->paddlenlp) (0.3.4)\n",
      "Requirement already satisfied, skipping upgrade: Jinja2>=2.10.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl->paddlenlp) (2.10.1)\n",
      "Requirement already satisfied, skipping upgrade: click>=5.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl->paddlenlp) (7.0)\n",
      "Requirement already satisfied, skipping upgrade: Werkzeug>=0.15 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl->paddlenlp) (0.16.0)\n",
      "Requirement already satisfied, skipping upgrade: itsdangerous>=0.24 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl->paddlenlp) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: pytz in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Flask-Babel>=1.0.0->visualdl->paddlenlp) (2019.3)\n",
      "Requirement already satisfied, skipping upgrade: Babel>=2.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Flask-Babel>=1.0.0->visualdl->paddlenlp) (2.8.0)\n",
      "Requirement already satisfied, skipping upgrade: pycodestyle<2.7.0,>=2.6.0a1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8>=3.7.9->visualdl->paddlenlp) (2.6.0)\n",
      "Requirement already satisfied, skipping upgrade: mccabe<0.7.0,>=0.6.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8>=3.7.9->visualdl->paddlenlp) (0.6.1)\n",
      "Requirement already satisfied, skipping upgrade: pyflakes<2.3.0,>=2.2.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8>=3.7.9->visualdl->paddlenlp) (2.2.0)\n",
      "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8>=3.7.9->visualdl->paddlenlp) (0.23)\n",
      "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl->paddlenlp) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl->paddlenlp) (2019.9.11)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl->paddlenlp) (1.25.6)\n",
      "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl->paddlenlp) (2.8)\n",
      "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->visualdl->paddlenlp) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->visualdl->paddlenlp) (0.10.0)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->visualdl->paddlenlp) (2.8.0)\n",
      "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->visualdl->paddlenlp) (2.4.2)\n",
      "Requirement already satisfied, skipping upgrade: future>=0.6.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from bce-python-sdk->visualdl->paddlenlp) (0.18.0)\n",
      "Requirement already satisfied, skipping upgrade: pycryptodome>=3.8.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from bce-python-sdk->visualdl->paddlenlp) (3.9.9)\n",
      "Requirement already satisfied, skipping upgrade: identify>=1.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl->paddlenlp) (1.4.10)\n",
      "Requirement already satisfied, skipping upgrade: toml in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl->paddlenlp) (0.10.0)\n",
      "Requirement already satisfied, skipping upgrade: virtualenv>=15.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl->paddlenlp) (16.7.9)\n",
      "Requirement already satisfied, skipping upgrade: cfgv>=2.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl->paddlenlp) (2.0.1)\n",
      "Requirement already satisfied, skipping upgrade: aspy.yaml in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl->paddlenlp) (1.3.0)\n",
      "Requirement already satisfied, skipping upgrade: nodeenv>=0.11.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl->paddlenlp) (1.3.4)\n",
      "Requirement already satisfied, skipping upgrade: pyyaml in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl->paddlenlp) (5.1.2)\n",
      "Requirement already satisfied, skipping upgrade: threadpoolctl>=2.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp) (2.1.0)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp) (0.14.1)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.19.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp) (1.6.3)\n",
      "Requirement already satisfied, skipping upgrade: MarkupSafe>=0.23 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Jinja2>=2.10.1->flask>=1.1.1->visualdl->paddlenlp) (1.1.1)\n",
      "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->flake8>=3.7.9->visualdl->paddlenlp) (0.6.0)\n",
      "Requirement already satisfied, skipping upgrade: setuptools in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib->visualdl->paddlenlp) (56.2.0)\n",
      "Requirement already satisfied, skipping upgrade: more-itertools in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from zipp>=0.5->importlib-metadata; python_version < \"3.8\"->flake8>=3.7.9->visualdl->paddlenlp) (7.2.0)\n",
      "/home/aistudio/multi-skill_dialogue\n"
     ]
    }
   ],
   "source": [
    "# 安装paddlenlp最新版本\n",
    "!pip install --upgrade paddlenlp -i https://pypi.org/simple\n",
    "\n",
    "%cd multi-skill_dialogue/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 多技能对话基线\n",
    "\n",
    "多技能对话比赛提供了多个子数据集，包含知识对话、推荐对话、画像对话和其他多种类型的对话数据集。基线采用UnifiedTransformer模型，模型的的输入除了数据token及`[CLS]`、`[SEP]`等special token之外，还有用于区别不同对话技能的special token。\n",
    "\n",
    "![模型输入](https://ai-studio-static-online.cdn.bcebos.com/24d697df544c4299a679e04e2d3b1442fdf17a14981e454e8a2de5c7acea8051)\n",
    "\n",
    "### 快速搭建基线Step1：数据预处理\n",
    "\n",
    "由于多技能对话比赛的[数据集](https://aistudio.baidu.com/aistudio/competition/detail/67)**数量多且数据规模大**，并且数据集之间**格式不同**，所以需要使用脚本对数据集进行预处理，同时将数据转化成id化的数据。\n",
    "\n",
    "**注意：** 需要确保脚本中的输入文件路径、输出文件路径和参数配置正确。由于数据规模较大，脚本运行时间较长(尤其是训练集)。也可自行分批次处理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total num : 250484 \n",
      "\ttruncate type 1: 5 rate(0.0000)\n",
      "\ttruncate tye 2: 66403 rate(0.2651)\n",
      "\ttruncate type 3: 3002 rate(0.0120)\n",
      "\ttruncate type 4: 28 rate(0.0001)\n",
      "Total num : 45334 \n",
      "\ttruncate type 1: 271 rate(0.0060)\n",
      "\ttruncate tye 2: 6561 rate(0.1447)\n",
      "\ttruncate type 3: 351 rate(0.0077)\n",
      "\ttruncate type 4: 63 rate(0.0014)\n",
      "Total num : 23090 \n",
      "\ttruncate type 1: 0 rate(0.0000)\n",
      "\ttruncate tye 2: 8429 rate(0.3650)\n",
      "\ttruncate type 3: 35 rate(0.0015)\n",
      "\ttruncate type 4: 0 rate(0.0000)\n"
     ]
    }
   ],
   "source": [
    "# 注意：脚本默认只取每个数据集的部分语料进行处理作为基线模型的训练数据，参赛选手需根据需求自行修改数据处理策略\r\n",
    "!python ./tools/convert_data_to_numerical.py ./tools/spm.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 快速搭建基线Step2：构建模型\n",
    "\n",
    "[UnifiedTransformer](https://github.com/PaddlePaddle/Knover/tree/luge-dialogue/luge-dialogue)以Transformer的编码器为网络基本组件，采用灵活的注意力机制，十分适合文本生成任务，并在模型输入中加入了标识不同对话技能的special token，使得模型能同时支持闲聊对话、推荐对话和知识对话。\n",
    "\n",
    "**PaddleNLP提供了UnifiedTransformer中文预训练模型，可以通过预训练模型名称完成一键加载。PaddleNLP为了方便用户处理数据，内置了与模型配套的Tokenizer，可以完成文本token化，token转ID，ID转token等操作。**\n",
    "\n",
    "PaddleNLP目前为UnifiedTransformer提供了两个中文预训练模型：\n",
    "- `unified_transformer-12L-cn` 该预训练模型是在大规模中文会话数据集上训练得到的\n",
    "- `unified_transformer-12L-cn-luge` 该预训练模型是`unified_transformer-12L-cn`在千言对话数据集上进行微调得到的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/utils.py:26: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  def convert_to_list(value, n, name, dtype=np.int):\n",
      "[2021-07-19 10:17:00,991] [    INFO] - Already cached /home/aistudio/.paddlenlp/models/unified_transformer-12L-cn-luge/unified_transformer-12L-cn-luge.pdparams\n",
      "[2021-07-19 10:17:11,870] [    INFO] - Found /home/aistudio/.paddlenlp/models/unified_transformer-12L-cn-luge/unified_transformer-12L-cn-vocab.txt\n",
      "[2021-07-19 10:17:11,873] [    INFO] - Found /home/aistudio/.paddlenlp/models/unified_transformer-12L-cn-luge/unified_transformer-12L-cn-spm.model\n"
     ]
    }
   ],
   "source": [
    "from paddlenlp.transformers import UnifiedTransformerLMHeadModel, UnifiedTransformerTokenizer\n",
    "\n",
    "# 预训练模型名称\n",
    "model_name_or_path = 'unified_transformer-12L-cn-luge'\n",
    "\n",
    "# 加载预训练模型\n",
    "model = UnifiedTransformerLMHeadModel.from_pretrained(model_name_or_path)\n",
    "# 加载配套的tokenizer\n",
    "tokenizer = UnifiedTransformerTokenizer.from_pretrained(model_name_or_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 快速搭建基线Step3：加载数据\n",
    "\n",
    "基线通过继承`paddle.io.IterableDataset`自定义可迭代数据集`DialogueDataset`，包括读取文件、shuffle及组batch等操作，细节详见`data.py`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from paddle.io import DataLoader\n",
    "from data import DialogueDataset\n",
    "\n",
    "# 训练batch_size\n",
    "batch_size = 8192\n",
    "# 组batch进行排序和shuffle的pool_size\n",
    "sort_pool_size = 65536\n",
    "\n",
    "# 训练集路径，注意与数据预处理输出路径保持一致\n",
    "train_data_path = './datasets/train.txt' \n",
    "# 初始化Dataset\n",
    "train_dataset = DialogueDataset(\n",
    "        train_data_path,\n",
    "        batch_size,\n",
    "        tokenizer.pad_token_id,\n",
    "        tokenizer.cls_token_id,\n",
    "        sort_pool_size,\n",
    "        mode='train')\n",
    "# 初始化Dataloader\n",
    "train_dataloader = DataLoader(train_dataset, return_list=True, batch_size=None)\n",
    "\n",
    "# 开发集路径，注意与数据预处理输出路径保持一致\n",
    "valid_data_path = './datasets/dev.txt' \n",
    "valid_dataset = DialogueDataset(\n",
    "    valid_data_path,\n",
    "    batch_size,\n",
    "    tokenizer.pad_token_id,\n",
    "    tokenizer.cls_token_id,\n",
    "    sort_pool_size,\n",
    "    mode='valid')\n",
    "valid_dataloader = DataLoader(valid_dataset, return_list=True, batch_size=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 快速搭建基线Step4：训练优化\n",
    "\n",
    "在该基线中，我们选择交叉熵损失函数，使用`paddle.optimizer.AdamW`作为优化器。\n",
    "\n",
    "在训练过程中，模型保存在当前目录checkpoints文件夹下。在训练的同时在验证集上进行评估，输出`loss`和`PPL`等指标。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\r\n",
    "\r\n",
    "# 定义训练模型保存函数\r\n",
    "def save_ckpt(model, tokenizer, save_dir, name):\r\n",
    "    output_dir = os.path.join(save_dir, \"model_{}\".format(name))\r\n",
    "    if not os.path.exists(output_dir):\r\n",
    "        os.makedirs(output_dir)\r\n",
    "    model.save_pretrained(output_dir)\r\n",
    "    tokenizer.save_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\r\n",
    "import paddle\r\n",
    "import paddle.nn.functional as F\r\n",
    "\r\n",
    "# 定义模型评估函数，在模型训练过程中会在开发集上对模型进行评估\r\n",
    "@paddle.no_grad()\r\n",
    "def evaluation(model, data_loader):\r\n",
    "    print('\\nEval begin...')\r\n",
    "    model.eval()\r\n",
    "    total_tokens = 0\r\n",
    "    total_loss = 0.0\r\n",
    "    start_time = time.time()\r\n",
    "    step = 0\r\n",
    "    for inputs in data_loader:\r\n",
    "        step += 1\r\n",
    "        token_ids, type_ids, pos_ids, generation_mask, tgt_label, tgt_pos = inputs\r\n",
    "\r\n",
    "        logits = model(token_ids, type_ids, pos_ids, generation_mask, tgt_pos)\r\n",
    "        loss = F.cross_entropy(logits, tgt_label, reduction='sum')\r\n",
    "\r\n",
    "        total_loss += loss.numpy()[0]\r\n",
    "        total_tokens += tgt_label.shape[0]\r\n",
    "\r\n",
    "    avg_loss = total_loss / total_tokens\r\n",
    "    ppl = math.exp(avg_loss)\r\n",
    "    avg_speed = (time.time() - start_time) / step\r\n",
    "    print('loss: %.4f - ppl: %.4f - %.3fs/step\\n' % (avg_loss, ppl, avg_speed))\r\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import paddle.nn as nn\r\n",
    "from paddle.optimizer.lr import NoamDecay\r\n",
    "from paddle.optimizer import AdamW\r\n",
    "\r\n",
    "# 学习率\r\n",
    "lr = 1e-5\r\n",
    "# 学习率逐渐升高到基础学习率（即上面配置的lr）所需要的迭代数\r\n",
    "warmup_steps = 4000\r\n",
    "# AdamW优化器中使用的weight_decay的系数\r\n",
    "weight_decay = 0.01\r\n",
    "# 度裁剪允许的最大梯度值\r\n",
    "max_grad_norm = 0.1\r\n",
    "\r\n",
    "# 初始化Noam衰减学习率的策略\r\n",
    "lr_scheduler = NoamDecay(1 / (warmup_steps * (lr**2)), warmup_steps)\r\n",
    "# 对偏置和LayerNorm层不进行weight_decay策略\r\n",
    "decay_params = [\r\n",
    "    p.name for n, p in model.named_parameters()\r\n",
    "    if not any(nd in n for nd in [\"bias\", \"norm\"])\r\n",
    "]\r\n",
    "# 初始化AdamW优化器\r\n",
    "optimizer = AdamW(\r\n",
    "    learning_rate=lr_scheduler,\r\n",
    "    parameters=model.parameters(),\r\n",
    "    weight_decay=weight_decay,\r\n",
    "    apply_decay_param_fun=lambda x: x in decay_params,\r\n",
    "    grad_clip=nn.ClipGradByGlobalNorm(max_grad_norm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/10\n",
      "step 50 - loss: 1.9291 - ppl: 6.8832 - lr: 0.0000001 - 0.728s/step\n",
      "step 100 - loss: 1.9400 - ppl: 6.9587 - lr: 0.0000002 - 0.484s/step\n",
      "\n",
      "Eval begin...\n",
      "loss: 2.7435 - ppl: 15.5418 - 0.164s/step\n",
      "\n",
      "step 150 - loss: 1.8874 - ppl: 6.6023 - lr: 0.0000004 - 0.484s/step\n",
      "step 200 - loss: 1.7354 - ppl: 5.6713 - lr: 0.0000005 - 0.487s/step\n",
      "\n",
      "Eval begin...\n",
      "loss: 2.7431 - ppl: 15.5343 - 0.165s/step\n",
      "\n",
      "step 250 - loss: 1.3325 - ppl: 3.7904 - lr: 0.0000006 - 0.495s/step\n",
      "step 300 - loss: 1.6799 - ppl: 5.3651 - lr: 0.0000008 - 0.487s/step\n",
      "\n",
      "Eval begin...\n",
      "loss: 2.7431 - ppl: 15.5354 - 0.165s/step\n",
      "\n",
      "step 350 - loss: 2.3642 - ppl: 10.6360 - lr: 0.0000009 - 0.487s/step\n",
      "step 400 - loss: 1.8773 - ppl: 6.5358 - lr: 0.0000010 - 0.485s/step\n",
      "\n",
      "Eval begin...\n",
      "loss: 2.7426 - ppl: 15.5273 - 0.166s/step\n",
      "\n",
      "step 450 - loss: 1.4364 - ppl: 4.2056 - lr: 0.0000011 - 0.487s/step\n",
      "step 500 - loss: 1.6333 - ppl: 5.1206 - lr: 0.0000013 - 0.482s/step\n",
      "\n",
      "Eval begin...\n",
      "loss: 2.7436 - ppl: 15.5429 - 0.164s/step\n",
      "\n",
      "step 550 - loss: 1.4205 - ppl: 4.1393 - lr: 0.0000014 - 0.484s/step\n",
      "step 600 - loss: 1.7098 - ppl: 5.5281 - lr: 0.0000015 - 0.489s/step\n",
      "\n",
      "Eval begin...\n",
      "loss: 2.7426 - ppl: 15.5270 - 0.164s/step\n",
      "\n",
      "step 650 - loss: 1.8144 - ppl: 6.1375 - lr: 0.0000016 - 0.488s/step\n",
      "step 700 - loss: 1.4310 - ppl: 4.1830 - lr: 0.0000017 - 0.487s/step\n",
      "\n",
      "Eval begin...\n",
      "loss: 2.7420 - ppl: 15.5179 - 0.165s/step\n",
      "\n",
      "step 750 - loss: 1.5211 - ppl: 4.5773 - lr: 0.0000019 - 0.492s/step\n",
      "step 800 - loss: 1.2582 - ppl: 3.5191 - lr: 0.0000020 - 0.488s/step\n",
      "\n",
      "Eval begin...\n",
      "loss: 2.7414 - ppl: 15.5090 - 0.165s/step\n",
      "\n",
      "step 850 - loss: 1.5849 - ppl: 4.8789 - lr: 0.0000021 - 0.485s/step\n",
      "step 900 - loss: 1.4181 - ppl: 4.1293 - lr: 0.0000023 - 0.489s/step\n",
      "\n",
      "Eval begin...\n",
      "loss: 2.7420 - ppl: 15.5182 - 0.165s/step\n",
      "\n",
      "step 950 - loss: 1.5329 - ppl: 4.6317 - lr: 0.0000024 - 0.484s/step\n",
      "step 1000 - loss: 1.5013 - ppl: 4.4877 - lr: 0.0000025 - 0.486s/step\n",
      "\n",
      "Eval begin...\n",
      "loss: 2.7413 - ppl: 15.5071 - 0.165s/step\n",
      "\n",
      "step 1050 - loss: 1.7752 - ppl: 5.9014 - lr: 0.0000026 - 0.487s/step\n",
      "step 1100 - loss: 1.6796 - ppl: 5.3635 - lr: 0.0000028 - 0.490s/step\n",
      "\n",
      "Eval begin...\n",
      "loss: 2.7425 - ppl: 15.5259 - 0.165s/step\n",
      "\n",
      "step 1150 - loss: 1.8898 - ppl: 6.6179 - lr: 0.0000029 - 0.488s/step\n",
      "step 1200 - loss: 1.3756 - ppl: 3.9573 - lr: 0.0000030 - 0.486s/step\n",
      "\n",
      "Eval begin...\n",
      "loss: 2.7409 - ppl: 15.5004 - 0.166s/step\n",
      "\n",
      "step 1250 - loss: 2.1915 - ppl: 8.9486 - lr: 0.0000031 - 0.492s/step\n",
      "step 1300 - loss: 1.7470 - ppl: 5.7371 - lr: 0.0000033 - 0.487s/step\n",
      "\n",
      "Eval begin...\n",
      "loss: 2.7407 - ppl: 15.4974 - 0.165s/step\n",
      "\n",
      "step 1350 - loss: 1.7676 - ppl: 5.8566 - lr: 0.0000034 - 0.487s/step\n",
      "step 1400 - loss: 1.3975 - ppl: 4.0449 - lr: 0.0000035 - 0.488s/step\n",
      "\n",
      "Eval begin...\n",
      "loss: 2.7396 - ppl: 15.4811 - 0.166s/step\n",
      "\n",
      "step 1450 - loss: 1.6433 - ppl: 5.1724 - lr: 0.0000036 - 0.488s/step\n",
      "step 1500 - loss: 1.4460 - ppl: 4.2460 - lr: 0.0000038 - 0.487s/step\n",
      "\n",
      "Eval begin...\n",
      "loss: 2.7404 - ppl: 15.4932 - 0.164s/step\n",
      "\n",
      "step 1550 - loss: 1.9353 - ppl: 6.9263 - lr: 0.0000039 - 0.488s/step\n",
      "step 1600 - loss: 1.7467 - ppl: 5.7355 - lr: 0.0000040 - 0.485s/step\n",
      "\n",
      "Eval begin...\n",
      "loss: 2.7399 - ppl: 15.4852 - 0.165s/step\n",
      "\n",
      "step 1650 - loss: 1.4766 - ppl: 4.3779 - lr: 0.0000041 - 0.491s/step\n",
      "step 1700 - loss: 2.0419 - ppl: 7.7050 - lr: 0.0000043 - 0.488s/step\n",
      "\n",
      "Eval begin...\n",
      "loss: 2.7397 - ppl: 15.4818 - 0.165s/step\n",
      "\n",
      "step 1750 - loss: 1.4225 - ppl: 4.1475 - lr: 0.0000044 - 0.488s/step\n",
      "step 1800 - loss: 2.0335 - ppl: 7.6409 - lr: 0.0000045 - 0.492s/step\n",
      "\n",
      "Eval begin...\n",
      "loss: 2.7396 - ppl: 15.4804 - 0.166s/step\n",
      "\n",
      "step 1850 - loss: 1.5258 - ppl: 4.5986 - lr: 0.0000046 - 0.491s/step\n",
      "step 1900 - loss: 1.4414 - ppl: 4.2266 - lr: 0.0000048 - 0.491s/step\n",
      "\n",
      "Eval begin...\n",
      "loss: 2.7414 - ppl: 15.5084 - 0.165s/step\n",
      "\n",
      "step 1950 - loss: 1.3399 - ppl: 3.8186 - lr: 0.0000049 - 0.489s/step\n",
      "step 2000 - loss: 1.2092 - ppl: 3.3507 - lr: 0.0000050 - 0.486s/step\n",
      "\n",
      "Eval begin...\n",
      "loss: 2.7384 - ppl: 15.4626 - 0.164s/step\n",
      "\n",
      "step 2050 - loss: 1.6841 - ppl: 5.3877 - lr: 0.0000051 - 0.489s/step\n",
      "step 2100 - loss: 1.6800 - ppl: 5.3658 - lr: 0.0000052 - 0.489s/step\n",
      "\n",
      "Eval begin...\n",
      "loss: 2.7392 - ppl: 15.4748 - 0.166s/step\n",
      "\n",
      "step 2150 - loss: 1.8261 - ppl: 6.2094 - lr: 0.0000054 - 0.488s/step\n",
      "step 2200 - loss: 1.2857 - ppl: 3.6171 - lr: 0.0000055 - 0.783s/step\n",
      "\n",
      "Eval begin...\n",
      "loss: 2.7429 - ppl: 15.5326 - 0.166s/step\n",
      "\n",
      "step 2250 - loss: 1.7162 - ppl: 5.5631 - lr: 0.0000056 - 0.503s/step\n",
      "step 2300 - loss: 1.1362 - ppl: 3.1149 - lr: 0.0000058 - 0.501s/step\n",
      "\n",
      "Eval begin...\n",
      "loss: 2.7392 - ppl: 15.4747 - 0.166s/step\n",
      "\n",
      "step 2350 - loss: 1.6018 - ppl: 4.9618 - lr: 0.0000059 - 0.500s/step\n",
      "step 2400 - loss: 1.6570 - ppl: 5.2437 - lr: 0.0000060 - 0.502s/step\n",
      "\n",
      "Eval begin...\n",
      "loss: 2.7395 - ppl: 15.4791 - 0.165s/step\n",
      "\n",
      "step 2450 - loss: 1.7128 - ppl: 5.5444 - lr: 0.0000061 - 0.499s/step\n",
      "step 2500 - loss: 1.8530 - ppl: 6.3790 - lr: 0.0000063 - 0.502s/step\n",
      "\n",
      "Eval begin...\n",
      "loss: 2.7406 - ppl: 15.4960 - 0.165s/step\n",
      "\n",
      "step 2550 - loss: 1.4387 - ppl: 4.2152 - lr: 0.0000064 - 0.503s/step\n",
      "step 2600 - loss: 1.3640 - ppl: 3.9117 - lr: 0.0000065 - 0.497s/step\n",
      "\n",
      "Eval begin...\n",
      "loss: 2.7394 - ppl: 15.4771 - 0.166s/step\n",
      "\n",
      "step 2650 - loss: 1.3488 - ppl: 3.8527 - lr: 0.0000066 - 0.503s/step\n",
      "step 2700 - loss: 1.8134 - ppl: 6.1315 - lr: 0.0000068 - 0.500s/step\n",
      "\n",
      "Eval begin...\n",
      "loss: 2.7394 - ppl: 15.4780 - 0.165s/step\n",
      "\n",
      "step 2750 - loss: 1.4311 - ppl: 4.1834 - lr: 0.0000069 - 0.500s/step\n",
      "step 2800 - loss: 2.3372 - ppl: 10.3525 - lr: 0.0000070 - 0.503s/step\n",
      "\n",
      "Eval begin...\n",
      "loss: 2.7392 - ppl: 15.4750 - 0.166s/step\n",
      "\n",
      "step 2850 - loss: 0.7948 - ppl: 2.2139 - lr: 0.0000071 - 0.503s/step\n",
      "step 2900 - loss: 1.6281 - ppl: 5.0944 - lr: 0.0000073 - 0.501s/step\n",
      "\n",
      "Eval begin...\n",
      "loss: 2.7406 - ppl: 15.4963 - 0.165s/step\n",
      "\n",
      "step 2950 - loss: 1.7923 - ppl: 6.0034 - lr: 0.0000074 - 0.496s/step\n",
      "step 3000 - loss: 1.2776 - ppl: 3.5881 - lr: 0.0000075 - 0.504s/step\n",
      "\n",
      "Eval begin...\n",
      "loss: 2.7374 - ppl: 15.4471 - 0.166s/step\n",
      "\n",
      "step 3050 - loss: 1.8158 - ppl: 6.1460 - lr: 0.0000076 - 0.503s/step\n",
      "step 3100 - loss: 1.0514 - ppl: 2.8615 - lr: 0.0000078 - 0.501s/step\n",
      "\n",
      "Eval begin...\n",
      "loss: 2.7377 - ppl: 15.4517 - 0.165s/step\n",
      "\n",
      "step 3150 - loss: 1.1459 - ppl: 3.1452 - lr: 0.0000079 - 0.504s/step\n",
      "step 3200 - loss: 1.9815 - ppl: 7.2536 - lr: 0.0000080 - 0.502s/step\n",
      "\n",
      "Eval begin...\n",
      "loss: 2.7403 - ppl: 15.4921 - 0.166s/step\n",
      "\n",
      "step 3250 - loss: 1.9419 - ppl: 6.9717 - lr: 0.0000081 - 0.499s/step\n",
      "step 3300 - loss: 1.6163 - ppl: 5.0345 - lr: 0.0000083 - 0.502s/step\n",
      "\n",
      "Eval begin...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-c61b86e7cc2b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msave_steps\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0;31m# 在开发集上对模型进行评估\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             \u001b[0mevaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m             \u001b[0;31m# 保存模型\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0msave_ckpt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-357>\u001b[0m in \u001b[0;36mevaluation\u001b[0;34m(model, data_loader)\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/base.py\u001b[0m in \u001b[0;36m_decorate_function\u001b[0;34m(func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_decorate_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mdecorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecorator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-9aacb83ddaa3>\u001b[0m in \u001b[0;36mevaluation\u001b[0;34m(model, data_loader)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mtoken_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgeneration_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_pos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgeneration_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_pos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sum'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    900\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_built\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 902\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    903\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mforward_post_hook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_post_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlenlp/transformers/unified_transformer/modeling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, token_type_ids, position_ids, attention_mask, masked_positions, use_cache, cache)\u001b[0m\n\u001b[1;32m    472\u001b[0m                                            use_cache, cache)\n\u001b[1;32m    473\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0muse_cache\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 474\u001b[0;31m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlm_head\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasked_positions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    475\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0muse_cache\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m             \u001b[0mcache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    900\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_built\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 902\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    903\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mforward_post_hook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_post_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlenlp/transformers/unified_transformer/modeling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, masked_positions)\u001b[0m\n\u001b[1;32m    384\u001b[0m                                            [-1, hidden_states.shape[-1]])\n\u001b[1;32m    385\u001b[0m             hidden_states = paddle.tensor.gather(hidden_states,\n\u001b[0;32m--> 386\u001b[0;31m                                                  masked_positions)\n\u001b[0m\u001b[1;32m    387\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/tensor/manipulation.py\u001b[0m in \u001b[0;36mgather\u001b[0;34m(x, index, axis, name)\u001b[0m\n\u001b[1;32m    843\u001b[0m     \u001b[0maxis_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    844\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 845\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpaddle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfluid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    846\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    847\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mdevice_guard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/nn.py\u001b[0m in \u001b[0;36mgather\u001b[0;34m(input, index, overwrite)\u001b[0m\n\u001b[1;32m   8289\u001b[0m     \"\"\"\n\u001b[1;32m   8290\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0min_dygraph_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 8291\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'overwrite'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   8292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8293\u001b[0m     check_variable_and_dtype(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# 训练轮次\n",
    "epochs = 10\n",
    "# 日志打印间隔\n",
    "logging_steps = 50\n",
    "# 模型保存及评估间隔\n",
    "save_steps = 100\n",
    "# 模型的保存路径\n",
    "save_dir = './checkpoints/'\n",
    "\n",
    "step = 0\n",
    "total_time = 0.0\n",
    "for epoch in range(epochs):\n",
    "    print('\\nEpoch %d/%d' % (epoch + 1, epochs))\n",
    "    batch_start_time = time.time()\n",
    "    for inputs in train_dataloader:\n",
    "        step += 1\n",
    "        token_ids, type_ids, pos_ids, generation_mask, tgt_label, tgt_pos = inputs\n",
    "\n",
    "        logits = model(token_ids, type_ids, pos_ids, generation_mask, tgt_pos)\n",
    "        # 使用交叉熵损失函数计算loss\n",
    "        loss = F.cross_entropy(logits, tgt_label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.clear_grad()\n",
    "\n",
    "        total_time += (time.time() - batch_start_time)\n",
    "        if step % logging_steps == 0:\n",
    "            ppl = paddle.exp(loss)\n",
    "            print('step %d - loss: %.4f - ppl: %.4f - lr: %.7f - %.3fs/step'\n",
    "                % (step, loss, ppl, optimizer.get_lr(), total_time / logging_steps))\n",
    "            total_time = 0.0\n",
    "        if step % save_steps == 0:\n",
    "            # 在开发集上对模型进行评估\n",
    "            evaluation(model, valid_dataloader)\n",
    "            # 保存模型\n",
    "            save_ckpt(model, tokenizer, save_dir, step)\n",
    "        batch_start_time = time.time()\n",
    "print(\"\\n=====training complete=====\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 快速搭建基线Step5：预测解码\n",
    "\n",
    "用训练保存的模型参数来初始化模型，加载测试集后即可进行预测。\n",
    "\n",
    "**PaddleNLP针对生成式任务提供了`generate`函数，支持Greedy Search、Beam Search和Sampling解码策略，用户只需指定解码策略以及相应的参数即可完成预测解码，得到生成的sequence的token ids以及概率得分。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-07-19 10:17:33,509] [    INFO] - Already cached /home/aistudio/.paddlenlp/models/unified_transformer-12L-cn-luge/unified_transformer-12L-cn-luge.pdparams\n"
     ]
    }
   ],
   "source": [
    "# 这里可以是paddlenlp提供的预训练模型名称，或者自己训练获得的微调模型路径\r\n",
    "model_name_or_path = 'unified_transformer-12L-cn-luge' \r\n",
    "# 加载模型\r\n",
    "model = UnifiedTransformerLMHeadModel.from_pretrained(model_name_or_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 预测batch_size\r\n",
    "batch_size = 4\r\n",
    "\r\n",
    "# 测试集路径，注意与数据预处理输出路径保持一致\r\n",
    "test_data_path = './datasets/test.txt' \r\n",
    "test_dataset = DialogueDataset(\r\n",
    "    test_data_path,\r\n",
    "    batch_size,\r\n",
    "    tokenizer.pad_token_id,\r\n",
    "    tokenizer.cls_token_id,\r\n",
    "    mode='test')\r\n",
    "test_dataloader = DataLoader(test_dataset, return_list=True, batch_size=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Infer begin...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/framework.py:687: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  elif dtype == np.bool:\n"
     ]
    }
   ],
   "source": [
    "import time\r\n",
    "from data import select_response\r\n",
    "\r\n",
    "# 预测解码生成序列的最大长度\r\n",
    "max_dec_len = 64\r\n",
    "# 预测解码生成序列的最小长度\r\n",
    "min_dec_len = 1\r\n",
    "# 解码策略\r\n",
    "decode_strategy = 'sampling'\r\n",
    "# topk-sampling解码参数top_k\r\n",
    "top_k = 5\r\n",
    "# 每条输入序列返回的输出序列个数，生成式API内部会将输入序列进行复制\r\n",
    "num_return_sequences = 20\r\n",
    "# 文本结果序列保存路径\r\n",
    "output_path = './predict.txt'\r\n",
    "# 日志打印间隔\r\n",
    "logging_steps = 10\r\n",
    "\r\n",
    "print('\\nInfer begin...')\r\n",
    "model.eval()\r\n",
    "total_time = 0.0\r\n",
    "start_time = time.time()\r\n",
    "responses = []\r\n",
    "for step, inputs in enumerate(test_dataloader, 1):\r\n",
    "    input_ids, token_type_ids, position_ids, attention_mask = inputs\r\n",
    "    ids, scores = model.generate(\r\n",
    "        input_ids=input_ids,\r\n",
    "        token_type_ids=token_type_ids,\r\n",
    "        position_ids=position_ids,\r\n",
    "        attention_mask=attention_mask,\r\n",
    "        max_length=max_dec_len,\r\n",
    "        min_length=min_dec_len,\r\n",
    "        decode_strategy=decode_strategy,\r\n",
    "        top_k=top_k,\r\n",
    "        num_return_sequences=num_return_sequences)\r\n",
    "\r\n",
    "    total_time += (time.time() - start_time)\r\n",
    "    if step % logging_steps == 0:\r\n",
    "        print('step %d - %.3fs/step' % (step, total_time / logging_steps))\r\n",
    "        total_time = 0.0\r\n",
    "    # 模型输出序列排序，从num_return_sequences个序列中选出最好的一个作为结果\r\n",
    "    results = select_response(ids, scores, tokenizer, max_dec_len, num_return_sequences)\r\n",
    "    responses.extend(results)\r\n",
    "\r\n",
    "    start_time = time.time()\r\n",
    "\r\n",
    "# 保存文本结果序列\r\n",
    "with open(output_path, 'w', encoding='utf-8') as fout:\r\n",
    "    for response in responses:\r\n",
    "        fout.write(response + '\\n')\r\n",
    "print('\\nSave inference result into: %s' % output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 快速搭建基线Step6：提交结果\n",
    "\n",
    "预测结果会被保存在`output_path`中，将预测结果准备成比赛官网要求的格式，提交到[比赛官网](https://aistudio.baidu.com/aistudio/competition/detail/67)进行评测即可。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "以上基线实现基于PaddleNLP，开源不易，希望大家多多支持~ \n",
    "**记得给[PaddleNLP](https://github.com/PaddlePaddle/PaddleNLP)点个小小的Star⭐**\n",
    "\n",
    "GitHub地址：[https://github.com/PaddlePaddle/PaddleNLP](https://github.com/PaddlePaddle/PaddleNLP)\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/a0e8ca7743ea4fe9aa741682a63e767f8c48dc55981f4e44a40e0e00d3ab369e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 2.0.0b0 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
