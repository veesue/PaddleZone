{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "使用官方baseline：[https://aistudio.baidu.com/aistudio/projectdetail/2017189](https://aistudio.baidu.com/aistudio/projectdetail/2017189)\n",
    "\n",
    "阅读理解是检索问答系统中的重要组成部分，最常见的数据集是单篇章、**抽取式**阅读理解数据集。  \n",
    "\n",
    "该示例展示了如何使用PaddleNLP快速实现基于预训练模型的机器阅读理解任务。\n",
    "\n",
    "本示例使用的数据集是Dureader<sub>robust</sub>数据集。对于一个给定的问题q和一个篇章p，根据篇章内容，给出该问题的答案a。数据集中的每个样本，是一个三元组<q, p, a>，例如：\n",
    "\n",
    "**问题 q**: 乔丹打了多少个赛季\n",
    "\n",
    "**篇章 p**: 迈克尔.乔丹在NBA打了15个赛季。他在84年进入nba，期间在1993年10月6日第一次退役改打棒球，95年3月18日重新回归，在99年1月13日第二次退役，后于2001年10月31日复出，在03年最终退役…\n",
    "\n",
    "**参考答案 a**: [‘15个’,‘15个赛季’]\n",
    "\n",
    "阅读理解模型的鲁棒性是衡量该技术能否在实际应用中大规模落地的重要指标之一。随着当前技术的进步，模型虽然能够在一些阅读理解测试集上取得较好的性能，但在实际应用中，这些模型所表现出的鲁棒性仍然难以令人满意。\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/67bb14fa9db64908ba03288ea1bcd49fb523f77f8adf43129293411b89a2f2a4)\n",
    "\n",
    "\n",
    "\n",
    "本示例使用的Dureader<sub>robust</sub>数据集作为首个关注阅读理解模型鲁棒性的中文数据集，旨在考察模型在真实应用场景中的过敏感性、过稳定性以及泛化能力等问题。\n",
    "\n",
    "关于该数据集的详细内容，可参考数据集[论文](https://arxiv.org/abs/2004.11142)，或官方[比赛链接](https://aistudio.baidu.com/aistudio/competition/detail/49?castk=LTE=)。\n",
    "\n",
    "## 安装说明\n",
    "\n",
    "* PaddlePaddle 安装\n",
    "\n",
    "   本项目依赖于 PaddlePaddle 2.0 及以上版本，请参考 [安装指南](https://www.paddlepaddle.org.cn/install/quick?docurl=/documentation/docs/zh/install/pip/windows-pip.html) 进行安装\n",
    "\n",
    "* PaddleNLP 安装\n",
    "\n",
    "   ```shell\n",
    "   pip install --upgrade paddlenlp -i https://pypi.org/simple\n",
    "   ```\n",
    "\n",
    "* 环境依赖\n",
    "\n",
    "    Python的版本要求 3.6+"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "AI Studio平台后续会默认安装PaddleNLP，在此之前可使用如下命令安装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: paddlenlp in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (2.0.3)\n",
      "Requirement already satisfied, skipping upgrade: visualdl in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (2.1.1)\n",
      "Requirement already satisfied, skipping upgrade: colorlog in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (4.1.0)\n",
      "Requirement already satisfied, skipping upgrade: h5py in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (2.9.0)\n",
      "Requirement already satisfied, skipping upgrade: jieba in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (0.42.1)\n",
      "Requirement already satisfied, skipping upgrade: seqeval in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (1.2.2)\n",
      "Requirement already satisfied, skipping upgrade: colorama in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (0.4.4)\n",
      "Requirement already satisfied, skipping upgrade: multiprocess in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (0.70.11.1)\n",
      "Requirement already satisfied, skipping upgrade: bce-python-sdk in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (0.8.53)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.14.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (1.15.0)\n",
      "Requirement already satisfied, skipping upgrade: Pillow>=7.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (7.1.2)\n",
      "Requirement already satisfied, skipping upgrade: flask>=1.1.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (1.1.1)\n",
      "Requirement already satisfied, skipping upgrade: pre-commit in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (1.21.0)\n",
      "Requirement already satisfied, skipping upgrade: shellcheck-py in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (0.7.1.1)\n",
      "Requirement already satisfied, skipping upgrade: requests in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (2.22.0)\n",
      "Requirement already satisfied, skipping upgrade: protobuf>=3.11.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (3.14.0)\n",
      "Requirement already satisfied, skipping upgrade: Flask-Babel>=1.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (1.0.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (1.20.3)\n",
      "Requirement already satisfied, skipping upgrade: flake8>=3.7.9 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (3.8.2)\n",
      "Requirement already satisfied, skipping upgrade: scikit-learn>=0.21.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from seqeval->paddlenlp) (0.24.2)\n",
      "Requirement already satisfied, skipping upgrade: dill>=0.3.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from multiprocess->paddlenlp) (0.3.3)\n",
      "Requirement already satisfied, skipping upgrade: pycryptodome>=3.8.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from bce-python-sdk->visualdl->paddlenlp) (3.9.9)\n",
      "Requirement already satisfied, skipping upgrade: future>=0.6.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from bce-python-sdk->visualdl->paddlenlp) (0.18.0)\n",
      "Requirement already satisfied, skipping upgrade: Werkzeug>=0.15 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl->paddlenlp) (0.16.0)\n",
      "Requirement already satisfied, skipping upgrade: itsdangerous>=0.24 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl->paddlenlp) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: click>=5.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl->paddlenlp) (7.0)\n",
      "Requirement already satisfied, skipping upgrade: Jinja2>=2.10.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl->paddlenlp) (2.10.1)\n",
      "Requirement already satisfied, skipping upgrade: pyyaml in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl->paddlenlp) (5.1.2)\n",
      "Requirement already satisfied, skipping upgrade: aspy.yaml in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl->paddlenlp) (1.3.0)\n",
      "Requirement already satisfied, skipping upgrade: cfgv>=2.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl->paddlenlp) (2.0.1)\n",
      "Requirement already satisfied, skipping upgrade: nodeenv>=0.11.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl->paddlenlp) (1.3.4)\n",
      "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl->paddlenlp) (0.23)\n",
      "Requirement already satisfied, skipping upgrade: virtualenv>=15.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl->paddlenlp) (16.7.9)\n",
      "Requirement already satisfied, skipping upgrade: toml in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl->paddlenlp) (0.10.0)\n",
      "Requirement already satisfied, skipping upgrade: identify>=1.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl->paddlenlp) (1.4.10)\n",
      "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl->paddlenlp) (2.8)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl->paddlenlp) (2019.9.11)\n",
      "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl->paddlenlp) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl->paddlenlp) (1.25.6)\n",
      "Requirement already satisfied, skipping upgrade: Babel>=2.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Flask-Babel>=1.0.0->visualdl->paddlenlp) (2.8.0)\n",
      "Requirement already satisfied, skipping upgrade: pytz in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Flask-Babel>=1.0.0->visualdl->paddlenlp) (2019.3)\n",
      "Requirement already satisfied, skipping upgrade: pyflakes<2.3.0,>=2.2.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8>=3.7.9->visualdl->paddlenlp) (2.2.0)\n",
      "Requirement already satisfied, skipping upgrade: mccabe<0.7.0,>=0.6.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8>=3.7.9->visualdl->paddlenlp) (0.6.1)\n",
      "Requirement already satisfied, skipping upgrade: pycodestyle<2.7.0,>=2.6.0a1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8>=3.7.9->visualdl->paddlenlp) (2.6.0)\n",
      "Requirement already satisfied, skipping upgrade: threadpoolctl>=2.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp) (2.1.0)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp) (0.14.1)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.19.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp) (1.6.3)\n",
      "Requirement already satisfied, skipping upgrade: MarkupSafe>=0.23 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Jinja2>=2.10.1->flask>=1.1.1->visualdl->paddlenlp) (1.1.1)\n",
      "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->pre-commit->visualdl->paddlenlp) (0.6.0)\n",
      "Requirement already satisfied, skipping upgrade: more-itertools in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from zipp>=0.5->importlib-metadata; python_version < \"3.8\"->pre-commit->visualdl->paddlenlp) (7.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade paddlenlp -i https://pypi.org/simple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 示例流程\n",
    "\n",
    "与大多数NLP任务相同，本次机器阅读理解任务的示例展示分为以下四步：\n",
    "\n",
    "首先我们从数据准备开始。\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/dd30e17318fb48fabb5701fd8a97be8176a1e372dd134cc0826e58cb5401933d)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 数据准备\n",
    "\n",
    "数据准备流程如下：\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/127ff46bf5c342889991438a95aa7158ec06c8852e58410ba7a516db330175f2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 1. 加载PaddleNLP内置数据集\n",
    "\n",
    "使用PaddleNLP提供的`load_dataset`API，即可一键完成数据集加载。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$recycle.bin文件夹可以删除么\n",
      "$RECYCLE.BIN 是 Win7、vista 的回收站，RECYCLER 是 XP 的回收站，如果是 xp、win7双系统机器，或者 xp、vista 双系统机器，xp 系统也会有$RECYCLE.BIN，这是系统文件，不是病毒，不需要删除。\n",
      "1\n",
      "\n",
      "+12黑铁装备强化卷成功几率高吗?\n",
      "保证上12几率很大。\n",
      "0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from paddlenlp.datasets import load_dataset\r\n",
    "\r\n",
    "train_ds, dev_ds, test_ds = load_dataset('dureader_yesno', splits=('train', 'dev', 'test'))\r\n",
    "\r\n",
    "for idx in range(2):\r\n",
    "    print(train_ds[idx]['question'])\r\n",
    "#    print(train_ds[idx]['paragraphs'])\r\n",
    "    print(train_ds[idx]['answer'])\r\n",
    "    print(train_ds[idx]['labels'])\r\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "关于更多PaddleNLP数据集，请参考[数据集列表](https://paddlenlp.readthedocs.io/zh/latest/data_prepare/dataset_list.html)\n",
    "\n",
    "如果你想使用自己的数据集文件构建数据集，请参考[以内置数据集格式读取本地数据集](https://paddlenlp.readthedocs.io/zh/latest/data_prepare/dataset_load.html#id4)和[自定义数据集](https://paddlenlp.readthedocs.io/zh/latest/data_prepare/dataset_self_defined.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 2. 加载 `paddlenlp.transformers.ErnieTokenizer`用于数据处理\n",
    "\n",
    "DuReader<sub>rubust</sub>数据集采用SQuAD数据格式，InputFeature使用滑动窗口的方法生成，即一个example可能对应多个InputFeature。\n",
    "\n",
    "由于文章加问题的文本长度可能大于max_seq_length，答案出现的位置有可能出现在文章最后，所以不能简单的对文章进行截断。\n",
    "\n",
    "那么对于过长的文章，则采用滑动窗口将文章分成多段，分别与问题组合。再用对应的tokenizer转化为模型可接受的feature。doc_stride参数就是每次滑动的距离。滑动窗口生成InputFeature的过程如下图：\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/5776cf9ec00546bca047a0930c8f56a8b64d723e0ff04f269334522954bb7d90)\n",
    "\n",
    "本基线中，我们使用的预训练模型是ERNIE，ERNIE对中文数据的处理是以字为单位。**PaddleNLP对于各种预训练模型已经内置了相应的tokenizer**，指定想要使用的模型名字即可加载对应的tokenizer。\n",
    "\n",
    "tokenizer的作用是将原始输入文本转化成模型可以接受的输入数据形式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-06-17 21:36:25,518] [    INFO] - Found /home/aistudio/.paddlenlp/models/ernie-1.0/vocab.txt\n"
     ]
    }
   ],
   "source": [
    "import paddlenlp\n",
    "\n",
    "# 设置模型名称\n",
    "MODEL_NAME = 'ernie-1.0'\n",
    "tokenizer = paddlenlp.transformers.ErnieTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 3. 调用`map()`方法批量处理数据\n",
    "\n",
    "由于我们传入了`lazy=False`，所以我们使用`load_dataset()`自定义的数据集是`MapDataset`对象。`MapDataset`是`paddle.io.Dataset`的功能增强版本。其内置的`map()`方法适合用来进行批量数据集处理。\n",
    "\n",
    "`map()`方法接受的主要参数是一个用于数据处理的function。正好可以与tokenizer相配合。\n",
    "\n",
    "以下是本示例中的用法："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'prepare_train_features' from 'utils' (/home/aistudio/utils.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-d3ae2483674e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprepare_train_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprepare_validation_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfunctools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpartial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmax_seq_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdoc_stride\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'prepare_train_features' from 'utils' (/home/aistudio/utils.py)"
     ]
    }
   ],
   "source": [
    "from utils import prepare_train_features, prepare_validation_features\r\n",
    "from functools import partial\r\n",
    "\r\n",
    "max_seq_length = 512\r\n",
    "doc_stride = 128\r\n",
    "\r\n",
    "train_trans_func = partial(prepare_train_features, \r\n",
    "                           max_seq_length=max_seq_length, \r\n",
    "                           doc_stride=doc_stride,\r\n",
    "                           tokenizer=tokenizer)\r\n",
    "\r\n",
    "train_ds.map(train_trans_func, batched=True, num_workers=4)\r\n",
    "\r\n",
    "dev_trans_func = partial(prepare_validation_features, \r\n",
    "                           max_seq_length=max_seq_length, \r\n",
    "                           doc_stride=doc_stride,\r\n",
    "                           tokenizer=tokenizer)\r\n",
    "                           \r\n",
    "dev_ds.map(dev_trans_func, batched=True, num_workers=4)\r\n",
    "test_ds.map(dev_trans_func, batched=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for idx in range(2):\n",
    "    print(train_ds[idx]['input_ids'])\n",
    "    print(train_ds[idx]['token_type_ids'])\n",
    "    print(train_ds[idx]['overflow_to_sample'])\n",
    "    print(train_ds[idx]['offset_mapping'])\n",
    "    print(train_ds[idx]['start_positions'])\n",
    "    print(train_ds[idx]['end_positions'])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "从以上结果可以看出，数据集中的example已经被转换成了模型可以接收的feature，包括input_ids、token_type_ids、答案的起始位置等信息。\n",
    "其中：\n",
    "\n",
    "* `input_ids`: 表示输入文本的token ID。\n",
    "* `token_type_ids`: 表示对应的token属于输入的问题还是答案。（Transformer类预训练模型支持单句以及句对输入）。\n",
    "* `overflow_to_sample`: feature对应的example的编号。\n",
    "* `offset_mapping`: 每个token的起始字符和结束字符在原文中对应的index（用于生成答案文本）。\n",
    "* `start_positions`: 答案在这个feature中的开始位置。\n",
    "* `end_positions`: 答案在这个feature中的结束位置。\n",
    "\n",
    "数据处理的详细过程请参见`utils.py`。\n",
    "\n",
    "更多有关数据处理的内容，请参考[数据处理](https://paddlenlp.readthedocs.io/zh/latest/data_prepare/data_preprocess.html)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 4. Batchify和数据读入\n",
    "\n",
    "使用`paddle.io.BatchSampler`和`paddlenlp.data`中提供的方法把数据组成batch。\n",
    "\n",
    "然后使用`paddle.io.DataLoader`接口多线程异步加载数据。\n",
    "\n",
    "`batchify_fn`详解：\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/30e43d4659384375a2a2c1b890ca5a995c4324d7168e49cebf1d2a1e99161f7d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import paddle\r\n",
    "from paddlenlp.data import Stack, Dict, Pad\r\n",
    "\r\n",
    "batch_size = 12\r\n",
    "\r\n",
    "# 定义BatchSampler\r\n",
    "train_batch_sampler = paddle.io.DistributedBatchSampler(\r\n",
    "        train_ds, batch_size=batch_size, shuffle=True)\r\n",
    "\r\n",
    "dev_batch_sampler = paddle.io.BatchSampler(\r\n",
    "    dev_ds, batch_size=batch_size, shuffle=False)\r\n",
    "\r\n",
    "test_batch_sampler = paddle.io.BatchSampler(\r\n",
    "    test_ds, batch_size=batch_size, shuffle=False)\r\n",
    "\r\n",
    "# 定义batchify_fn\r\n",
    "train_batchify_fn = lambda samples, fn=Dict({\r\n",
    "    \"input_ids\": Pad(axis=0, pad_val=tokenizer.pad_token_id),\r\n",
    "    \"token_type_ids\": Pad(axis=0, pad_val=tokenizer.pad_token_type_id),\r\n",
    "    \"start_positions\": Stack(dtype=\"int64\"),\r\n",
    "    \"end_positions\": Stack(dtype=\"int64\")\r\n",
    "}): fn(samples)\r\n",
    "\r\n",
    "dev_batchify_fn = lambda samples, fn=Dict({\r\n",
    "    \"input_ids\": Pad(axis=0, pad_val=tokenizer.pad_token_id),\r\n",
    "    \"token_type_ids\": Pad(axis=0, pad_val=tokenizer.pad_token_type_id)\r\n",
    "}): fn(samples)\r\n",
    "\r\n",
    "# 构造DataLoader\r\n",
    "train_data_loader = paddle.io.DataLoader(\r\n",
    "    dataset=train_ds,\r\n",
    "    batch_sampler=train_batch_sampler,\r\n",
    "    collate_fn=train_batchify_fn,\r\n",
    "    return_list=True)\r\n",
    "\r\n",
    "dev_data_loader = paddle.io.DataLoader(\r\n",
    "    dataset=dev_ds,\r\n",
    "    batch_sampler=dev_batch_sampler,\r\n",
    "    collate_fn=dev_batchify_fn,\r\n",
    "    return_list=True)\r\n",
    "\r\n",
    "test_data_loader = paddle.io.DataLoader(\r\n",
    "    dataset=test_ds,\r\n",
    "    batch_sampler=test_batch_sampler,\r\n",
    "    collate_fn=dev_batchify_fn,\r\n",
    "    return_list=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "更多PaddleNLP内置的batchify相关API，请参考[collate](https://paddlenlp.readthedocs.io/zh/latest/source/paddlenlp.data.collate.html)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "到这里数据集准备就全部完成了，下一步我们需要组网并设计loss function。\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/fdcb44a00ede4ce08ae2652931556fb58cc903f686bf491792489353d2800e7d)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 模型结构\n",
    "\n",
    "## 使用PaddleNLP一键加载预训练模型\n",
    "\n",
    "以下项目以ERNIE为例，介绍如何将预训练模型Fine-tune完成DuReader<sub>robust</sub>阅读理解任务。\n",
    "\n",
    "DuReader<sub>robust</sub>阅读理解任务的本质是答案抽取任务。根据输入的问题和文章，从预训练模型的**sequence_output**中预测答案在文章中的起始位置和结束位置。原理如下图所示：\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/bb1396fc12614dbabcfb4fcfafe9346507d4d65d0a194d75aba04b9d31bace6b)\n",
    "\n",
    "目前PaddleNLP已经内置了包括ERNIE在内的多种基于预训练模型的常用任务的下游网络，包括机器阅读理解。\n",
    "\n",
    "这些网络在`paddlenlp.transformers`下，均可实现一键调用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from paddlenlp.transformers import ErnieForQuestionAnswering\r\n",
    "\r\n",
    "model = ErnieForQuestionAnswering.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 设计loss function\n",
    "\n",
    "模型的网络结构确定后我们就可以设计loss function了。\n",
    "\n",
    "ErineForQuestionAnswering模型对将ErnieModel的sequence_output拆开成start_logits和end_logits输出，所以DuReader<sub>robust</sub>的loss由start_loss和end_loss两部分组成，我们需要自己定义loss function。\n",
    "\n",
    "对于答案起始位置和结束位置的预测可以分别看成两个分类任务。所以设计的loss function如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class CrossEntropyLossForRobust(paddle.nn.Layer):\r\n",
    "    def __init__(self):\r\n",
    "        super(CrossEntropyLossForRobust, self).__init__()\r\n",
    "\r\n",
    "    def forward(self, y, label):\r\n",
    "        start_logits, end_logits = y\r\n",
    "        start_position, end_position = label\r\n",
    "        start_position = paddle.unsqueeze(start_position, axis=-1)\r\n",
    "        end_position = paddle.unsqueeze(end_position, axis=-1)\r\n",
    "        start_loss = paddle.nn.functional.cross_entropy(\r\n",
    "            input=start_logits, label=start_position)\r\n",
    "        end_loss = paddle.nn.functional.cross_entropy(\r\n",
    "            input=end_logits, label=end_position)\r\n",
    "        loss = (start_loss + end_loss) / 2\r\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "选择网络结构后，我们需要设置Fine-Tune优化策略。\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/7eca6595f338409498149cb586c077ba4933739810cf436080a2292be7e0a92d)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 设置Fine-Tune优化策略\n",
    "适用于ERNIE/BERT这类Transformer模型的学习率为warmup的动态学习率。\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"https://ai-studio-static-online.cdn.bcebos.com/2bc624280a614a80b5449773192be460f195b13af89e4e5cbaf62bf6ac16de2c\" width=\"40%\" height=\"30%\"/> <br />\n",
    "</p>\n",
    "<br><center>图3：动态学习率示意图</center></br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 训练过程中的最大学习率\r\n",
    "learning_rate = 3e-5 \r\n",
    "\r\n",
    "# 训练轮次\r\n",
    "epochs = 2\r\n",
    "\r\n",
    "# 学习率预热比例\r\n",
    "warmup_proportion = 0.1\r\n",
    "\r\n",
    "# 权重衰减系数，类似模型正则项策略，避免模型过拟合\r\n",
    "weight_decay = 0.01\r\n",
    "\r\n",
    "num_training_steps = len(train_data_loader) * epochs\r\n",
    "\r\n",
    "# 学习率衰减策略\r\n",
    "lr_scheduler = paddlenlp.transformers.LinearDecayWithWarmup(learning_rate, num_training_steps, warmup_proportion)\r\n",
    "\r\n",
    "decay_params = [\r\n",
    "    p.name for n, p in model.named_parameters()\r\n",
    "    if not any(nd in n for nd in [\"bias\", \"norm\"])\r\n",
    "]\r\n",
    "optimizer = paddle.optimizer.AdamW(\r\n",
    "    learning_rate=lr_scheduler,\r\n",
    "    parameters=model.parameters(),\r\n",
    "    weight_decay=weight_decay,\r\n",
    "    apply_decay_param_fun=lambda x: x in decay_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "现在万事俱备，我们可以开始训练阅读理解模型啦。\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/6975542d488f4f75b385fe75d574a3aaa8e208f5e99f4acd8a8e8aea3b85c058)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 模型训练与评估\n",
    "\n",
    "\n",
    "模型训练的过程通常有以下步骤：\n",
    "\n",
    "1. 从dataloader中取出一个batch data。\n",
    "2. 将batch data喂给model，做前向计算。\n",
    "3. 将前向计算结果传给损失函数，计算loss。\n",
    "4. loss反向回传，更新梯度。重复以上步骤。\n",
    "\n",
    "每训练一个epoch时，程序通过evaluate()调用paddlenlp.metric.squad中的squad_evaluate(), compute_predictions()评估当前模型训练的效果，其中：\n",
    "\n",
    "* compute_predictions()用于生成可提交的答案；\n",
    "\n",
    "* squad_evaluate()用于返回评价指标。\n",
    "\n",
    "二者适用于所有符合squad数据格式的答案抽取任务。这类任务使用F1和exact来评估预测的答案和真实答案的相似程度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from utils import evaluate\r\n",
    "\r\n",
    "criterion = CrossEntropyLossForRobust()\r\n",
    "global_step = 0\r\n",
    "for epoch in range(1, epochs + 1):\r\n",
    "    for step, batch in enumerate(train_data_loader, start=1):\r\n",
    "\r\n",
    "        global_step += 1\r\n",
    "        input_ids, segment_ids, start_positions, end_positions = batch\r\n",
    "        logits = model(input_ids=input_ids, token_type_ids=segment_ids)\r\n",
    "        loss = criterion(logits, (start_positions, end_positions))\r\n",
    "\r\n",
    "        if global_step % 100 == 0 :\r\n",
    "            print(\"global step %d, epoch: %d, batch: %d, loss: %.5f\" % (global_step, epoch, step, loss))\r\n",
    "\r\n",
    "        loss.backward()\r\n",
    "        optimizer.step()\r\n",
    "        lr_scheduler.step()\r\n",
    "        optimizer.clear_grad()\r\n",
    "\r\n",
    "evaluate(model=model, data_loader=dev_data_loader) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 传入test_data_loader，并将is_test参数设为True，即可生成千言比赛可提交的结果。\r\n",
    "evaluate(model=model, data_loader=test_data_loader, is_test=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "以上基线实现基于PaddleNLP，开源不易，希望大家多多支持~ \n",
    "**记得给[PaddleNLP](https://github.com/PaddlePaddle/PaddleNLP)点个小小的Star⭐**\n",
    "\n",
    "GitHub地址：[https://github.com/PaddlePaddle/PaddleNLP](https://github.com/PaddlePaddle/PaddleNLP)\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/a0e8ca7743ea4fe9aa741682a63e767f8c48dc55981f4e44a40e0e00d3ab369e)\n",
    "\n",
    "**更多使用方法可参考PaddleNLP教程**\n",
    "\n",
    "- [使用seq2vec模块进行句子情感分类](https://aistudio.baidu.com/aistudio/projectdetail/1283423)\n",
    "- [使用预训练模型ERNIE优化情感分析](https://aistudio.baidu.com/aistudio/projectdetail/1294333)\n",
    "- [使用BiGRU-CRF模型完成快递单信息抽取](https://aistudio.baidu.com/aistudio/projectdetail/1317771)\n",
    "- [使用预训练模型ERNIE优化快递单信息抽取](https://aistudio.baidu.com/aistudio/projectdetail/1329361)\n",
    "- [使用Seq2Seq模型完成自动对联](https://aistudio.baidu.com/aistudio/projectdetail/1321118)\n",
    "- [使用预训练模型ERNIE-GEN自动写诗](https://aistudio.baidu.com/aistudio/projectdetail/1339888)\n",
    "- [使用TCN网络完成新冠疫情病例数预测](https://aistudio.baidu.com/aistudio/projectdetail/1290873)\n",
    "- [自定义数据集实现文本多分类任务](https://aistudio.baidu.com/aistudio/projectdetail/1468469)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 加入交流群，一起学习吧\n",
    "\n",
    "现在就加入PaddleNLP的QQ技术交流群，一起交流NLP技术吧！\n",
    "\n",
    "<img src=\"https://ai-studio-static-online.cdn.bcebos.com/d953727af0c24a7c806ab529495f0904f22f809961be420b8c88cdf59b837394\" width=\"200\" height=\"250\" >"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 2.1.0 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
