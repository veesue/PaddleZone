{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "使用我爱志方小姐大佬的baseline：[https://aistudio.baidu.com/aistudio/projectdetail/2085423](https://aistudio.baidu.com/aistudio/projectdetail/2085423)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))': /simple/paddlenlp/\u001b[0m\n",
      "\u001b[33mWARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))': /simple/paddlenlp/\u001b[0m\n",
      "\u001b[33mWARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))': /simple/paddlenlp/\u001b[0m\n",
      "Requirement already up-to-date: paddlenlp in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (2.0.5)\n",
      "Requirement already satisfied, skipping upgrade: h5py in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (2.9.0)\n",
      "Requirement already satisfied, skipping upgrade: colorlog in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (4.1.0)\n",
      "Requirement already satisfied, skipping upgrade: visualdl in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (2.2.0)\n",
      "Requirement already satisfied, skipping upgrade: multiprocess in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (0.70.11.1)\n",
      "Requirement already satisfied, skipping upgrade: jieba in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (0.42.1)\n",
      "Requirement already satisfied, skipping upgrade: colorama in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (0.4.4)\n",
      "Requirement already satisfied, skipping upgrade: seqeval in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (1.2.2)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.7 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from h5py->paddlenlp) (1.20.3)\n",
      "Requirement already satisfied, skipping upgrade: six in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from h5py->paddlenlp) (1.15.0)\n",
      "Requirement already satisfied, skipping upgrade: bce-python-sdk in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (0.8.53)\n",
      "Requirement already satisfied, skipping upgrade: requests in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (2.22.0)\n",
      "Requirement already satisfied, skipping upgrade: protobuf>=3.11.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (3.14.0)\n",
      "Requirement already satisfied, skipping upgrade: pandas in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (1.1.5)\n",
      "Requirement already satisfied, skipping upgrade: Flask-Babel>=1.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (1.0.0)\n",
      "Requirement already satisfied, skipping upgrade: Pillow>=7.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (7.1.2)\n",
      "Requirement already satisfied, skipping upgrade: flask>=1.1.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (1.1.1)\n",
      "Requirement already satisfied, skipping upgrade: flake8>=3.7.9 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (3.8.2)\n",
      "Requirement already satisfied, skipping upgrade: matplotlib in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (2.2.3)\n",
      "Requirement already satisfied, skipping upgrade: pre-commit in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (1.21.0)\n",
      "Requirement already satisfied, skipping upgrade: shellcheck-py in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (0.7.1.1)\n",
      "Requirement already satisfied, skipping upgrade: dill>=0.3.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from multiprocess->paddlenlp) (0.3.3)\n",
      "Requirement already satisfied, skipping upgrade: scikit-learn>=0.21.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from seqeval->paddlenlp) (0.24.2)\n",
      "Requirement already satisfied, skipping upgrade: future>=0.6.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from bce-python-sdk->visualdl->paddlenlp) (0.18.0)\n",
      "Requirement already satisfied, skipping upgrade: pycryptodome>=3.8.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from bce-python-sdk->visualdl->paddlenlp) (3.9.9)\n",
      "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl->paddlenlp) (2.8)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl->paddlenlp) (1.25.6)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl->paddlenlp) (2019.9.11)\n",
      "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl->paddlenlp) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pandas->visualdl->paddlenlp) (2019.3)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.7.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pandas->visualdl->paddlenlp) (2.8.0)\n",
      "Requirement already satisfied, skipping upgrade: Jinja2>=2.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Flask-Babel>=1.0.0->visualdl->paddlenlp) (2.10.1)\n",
      "Requirement already satisfied, skipping upgrade: Babel>=2.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Flask-Babel>=1.0.0->visualdl->paddlenlp) (2.8.0)\n",
      "Requirement already satisfied, skipping upgrade: itsdangerous>=0.24 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl->paddlenlp) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: click>=5.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl->paddlenlp) (7.0)\n",
      "Requirement already satisfied, skipping upgrade: Werkzeug>=0.15 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl->paddlenlp) (0.16.0)\n",
      "Requirement already satisfied, skipping upgrade: pyflakes<2.3.0,>=2.2.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8>=3.7.9->visualdl->paddlenlp) (2.2.0)\n",
      "Requirement already satisfied, skipping upgrade: mccabe<0.7.0,>=0.6.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8>=3.7.9->visualdl->paddlenlp) (0.6.1)\n",
      "Requirement already satisfied, skipping upgrade: pycodestyle<2.7.0,>=2.6.0a1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8>=3.7.9->visualdl->paddlenlp) (2.6.0)\n",
      "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8>=3.7.9->visualdl->paddlenlp) (0.23)\n",
      "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->visualdl->paddlenlp) (2.4.2)\n",
      "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->visualdl->paddlenlp) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->visualdl->paddlenlp) (0.10.0)\n",
      "Requirement already satisfied, skipping upgrade: identify>=1.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl->paddlenlp) (1.4.10)\n",
      "Requirement already satisfied, skipping upgrade: nodeenv>=0.11.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl->paddlenlp) (1.3.4)\n",
      "Requirement already satisfied, skipping upgrade: pyyaml in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl->paddlenlp) (5.1.2)\n",
      "Requirement already satisfied, skipping upgrade: cfgv>=2.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl->paddlenlp) (2.0.1)\n",
      "Requirement already satisfied, skipping upgrade: virtualenv>=15.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl->paddlenlp) (16.7.9)\n",
      "Requirement already satisfied, skipping upgrade: toml in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl->paddlenlp) (0.10.0)\n",
      "Requirement already satisfied, skipping upgrade: aspy.yaml in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl->paddlenlp) (1.3.0)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.19.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp) (1.6.3)\n",
      "Requirement already satisfied, skipping upgrade: threadpoolctl>=2.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp) (2.1.0)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp) (0.14.1)\n",
      "Requirement already satisfied, skipping upgrade: MarkupSafe>=0.23 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Jinja2>=2.5->Flask-Babel>=1.0.0->visualdl->paddlenlp) (1.1.1)\n",
      "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->flake8>=3.7.9->visualdl->paddlenlp) (0.6.0)\n",
      "Requirement already satisfied, skipping upgrade: setuptools in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib->visualdl->paddlenlp) (56.2.0)\n",
      "Requirement already satisfied, skipping upgrade: more-itertools in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from zipp>=0.5->importlib-metadata; python_version < \"3.8\"->flake8>=3.7.9->visualdl->paddlenlp) (7.2.0)\n"
     ]
    }
   ],
   "source": [
    "\r\n",
    "!pip install --upgrade paddlenlp -i https://pypi.org/simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "import paddle\n",
    "from paddle.io import BatchSampler\n",
    "from paddle.io import DataLoader\n",
    "from paddle.metric import Accuracy\n",
    "from paddle.nn import CrossEntropyLoss\n",
    "from paddle.optimizer import AdamW\n",
    "from paddlenlp.data import Dict\n",
    "from paddlenlp.data import Pad\n",
    "from paddlenlp.data import Stack\n",
    "from paddlenlp.datasets import load_dataset\n",
    "from paddlenlp.transformers import BertTokenizer\n",
    "from paddlenlp.transformers import BertForSequenceClassification\n",
    "from paddlenlp.transformers import ErnieTokenizer\n",
    "from paddlenlp.transformers import ErnieForSequenceClassification\n",
    "from paddlenlp.transformers import ErnieGramTokenizer\n",
    "from paddlenlp.transformers import ErnieGramForSequenceClassification\n",
    "from paddlenlp.transformers import RobertaTokenizer\n",
    "from paddlenlp.transformers import RobertaForSequenceClassification\n",
    "from paddlenlp.transformers import LinearDecayWithWarmup\n",
    "\n",
    "from config import Config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MODEL_CLASSES = {\n",
    "    'bert': (BertForSequenceClassification, BertTokenizer),\n",
    "    'ernie': (ErnieForSequenceClassification, ErnieTokenizer),\n",
    "    'ernie_gram': (ErnieGramForSequenceClassification, ErnieGramTokenizer),\n",
    "    'roberta': (RobertaForSequenceClassification, RobertaTokenizer)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lable_list_length = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def set_seed(args):\n",
    "    random.seed(args.seed)\n",
    "    np.random.seed(args.seed)\n",
    "    paddle.seed(args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def convert_example(example, tokenizer):\r\n",
    "    \"\"\"convert a Dureader-yesno example into necessary features\"\"\"\r\n",
    "\r\n",
    "    feature = tokenizer(\r\n",
    "        text=example['question'],\r\n",
    "        text_pair=example['answer'],\r\n",
    "        max_seq_len=args.max_seq_length\r\n",
    "    )\r\n",
    "    feature['labels'] = example['labels']\r\n",
    "    feature['id'] = example['id']\r\n",
    "\r\n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@paddle.no_grad()\r\n",
    "def evaluate(model, metric, data_loader):\r\n",
    "    model.eval()\r\n",
    "    metric.reset()\r\n",
    "    for batch in data_loader:\r\n",
    "        input_ids, segment_ids, labels = batch\r\n",
    "        logits = model(input_ids, segment_ids)\r\n",
    "        correct = metric.compute(logits, labels)\r\n",
    "        metric.update(correct)\r\n",
    "        accu = metric.accumulate()\r\n",
    "\r\n",
    "    # print(\"accu: %f\" % (accu))\r\n",
    "    model.train()  # Switch the model to training mode after evaluation\r\n",
    "\r\n",
    "    return accu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@paddle.no_grad()\r\n",
    "def predict(model, data_loader):\r\n",
    "    model.eval()\r\n",
    "    res = {}\r\n",
    "    for batch in data_loader:\r\n",
    "        input_ids, segment_ids, qas_id = batch\r\n",
    "        logits = model(input_ids, segment_ids)\r\n",
    "        qas_id = qas_id.numpy()\r\n",
    "        preds = paddle.argmax(logits, axis=1).numpy()\r\n",
    "        for i in range(len(preds)):\r\n",
    "            res[str(qas_id[i])] = data_loader.dataset.label_list[preds[i]]\r\n",
    "    model.train()\r\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def do_train(args):\r\n",
    "\r\n",
    "    global lable_list_length\r\n",
    "    \r\n",
    "    paddle.set_device(args.device)\r\n",
    "\r\n",
    "    args.model_type = args.model_type.lower()\r\n",
    "    model_class, tokenizer_class = MODEL_CLASSES[args.model_type]\r\n",
    "    tokenizer = tokenizer_class.from_pretrained(args.model_name_or_path)\r\n",
    "\r\n",
    "    set_seed(args)\r\n",
    "\r\n",
    "    train_ds, dev_ds = load_dataset('dureader_yesno', splits=['train', 'dev'])\r\n",
    "\r\n",
    "    trans_func = partial(convert_example, tokenizer=tokenizer)\r\n",
    "\r\n",
    "    train_batchify_fn = lambda samples, fn=Dict({\r\n",
    "        'input_ids': Pad(axis=0, pad_val=tokenizer.pad_token_id),\r\n",
    "        'token_type_ids': Pad(axis=0, pad_val=tokenizer.pad_token_type_id),\r\n",
    "        'labels': Stack(dtype=\"int64\")\r\n",
    "    }): fn(samples)\r\n",
    "\r\n",
    "    train_ds = train_ds.map(trans_func, lazy=True)\r\n",
    "    train_batch_sampler = BatchSampler(\r\n",
    "        dataset=train_ds, \r\n",
    "        batch_size=args.batch_size, \r\n",
    "        shuffle=True\r\n",
    "    )\r\n",
    "    train_data_loader = DataLoader(\r\n",
    "        dataset=train_ds,\r\n",
    "        batch_sampler=train_batch_sampler,\r\n",
    "        collate_fn=train_batchify_fn,\r\n",
    "        return_list=True\r\n",
    "    )\r\n",
    "\r\n",
    "    dev_ds = dev_ds.map(trans_func, lazy=True)\r\n",
    "    dev_batch_sampler = BatchSampler(\r\n",
    "        dataset=dev_ds, \r\n",
    "        batch_size=args.batch_size, \r\n",
    "        shuffle=False\r\n",
    "    )\r\n",
    "    dev_data_loader = DataLoader(\r\n",
    "        dataset=dev_ds,\r\n",
    "        batch_sampler=dev_batch_sampler,\r\n",
    "        collate_fn=train_batchify_fn,\r\n",
    "        return_list=True\r\n",
    "    )\r\n",
    "\r\n",
    "    lable_list_length = len(train_ds.label_list)\r\n",
    "    model = model_class.from_pretrained(\r\n",
    "        args.model_name_or_path, num_classes=lable_list_length)\r\n",
    "\r\n",
    "    num_training_steps = args.max_steps if args.max_steps > 0 else len(\r\n",
    "        train_data_loader) * args.num_train_epochs\r\n",
    "    num_train_epochs = math.ceil(num_training_steps / len(train_data_loader))\r\n",
    "\r\n",
    "    num_batchs = len(train_data_loader)\r\n",
    "\r\n",
    "    lr_scheduler = LinearDecayWithWarmup(\r\n",
    "        learning_rate=args.learning_rate, \r\n",
    "        total_steps=num_training_steps,\r\n",
    "        warmup=args.warmup_proportion\r\n",
    "    )\r\n",
    "    # Generate parameter names needed to perform weight decay.\r\n",
    "    # All bias and LayerNorm parameters are excluded.\r\n",
    "    decay_params = [\r\n",
    "        p.name for n, p in model.named_parameters()\r\n",
    "        if not any(nd in n for nd in [\"bias\", \"norm\"])\r\n",
    "    ]\r\n",
    "    optimizer = paddle.optimizer.AdamW(\r\n",
    "        learning_rate=lr_scheduler,\r\n",
    "        epsilon=args.adam_epsilon,\r\n",
    "        parameters=model.parameters(),\r\n",
    "        weight_decay=args.weight_decay,\r\n",
    "        apply_decay_param_fun=lambda x: x in decay_params\r\n",
    "    )\r\n",
    "\r\n",
    "    criterion = CrossEntropyLoss()\r\n",
    "    metric = Accuracy()\r\n",
    "\r\n",
    "    best_val_acc = 0.0\r\n",
    "\r\n",
    "    output_dir = os.path.join(args.output_dir, \"bets_model\")\r\n",
    "    if not os.path.exists(output_dir):\r\n",
    "        os.makedirs(output_dir)\r\n",
    "\r\n",
    "    global_step = 0\r\n",
    "    tic_train = time.time()\r\n",
    "    for epoch in range(num_train_epochs):\r\n",
    "        for step, batch in enumerate(train_data_loader):\r\n",
    "            \r\n",
    "            global_step += 1\r\n",
    "\r\n",
    "            input_ids, segment_ids, label = batch\r\n",
    "\r\n",
    "            logits = model(input_ids=input_ids, token_type_ids=segment_ids)\r\n",
    "            loss = criterion(logits, label)\r\n",
    "\r\n",
    "            if global_step % args.logging_steps == 0:\r\n",
    "                print(\r\n",
    "                    \"global step %d, epoch: %d, batch: %d/%d, loss: %f, speed: %.2f step/s\"\r\n",
    "                    % (global_step, epoch + 1, step + 1, num_batchs, loss,\r\n",
    "                       args.logging_steps / (time.time() - tic_train)))\r\n",
    "                \r\n",
    "                tic_train = time.time()\r\n",
    "\r\n",
    "            loss.backward()\r\n",
    "            optimizer.step()\r\n",
    "            lr_scheduler.step()\r\n",
    "            optimizer.clear_grad()\r\n",
    "\r\n",
    "            if global_step % args.save_steps == 0 or global_step == num_training_steps:\r\n",
    "                acc = evaluate(model, metric, dev_data_loader)\r\n",
    "                print(f'global step {global_step}, val acc is {acc:.5f}!')\r\n",
    "                \r\n",
    "                if acc > best_val_acc:\r\n",
    "                    best_val_acc = acc\r\n",
    "\r\n",
    "                    print(f'save model at global step {global_step}, best val acc is {best_val_acc:.5f}!')\r\n",
    "\r\n",
    "                    model.save_pretrained(output_dir)\r\n",
    "                    tokenizer.save_pretrained(output_dir)\r\n",
    "\r\n",
    "                if global_step == num_training_steps:\r\n",
    "                    break\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def do_predict(args):\r\n",
    "\r\n",
    "    global lable_list_length\r\n",
    "\r\n",
    "    output_dir = os.path.join(args.output_dir, \"bets_model\")\r\n",
    "\r\n",
    "    model_class, tokenizer_class = MODEL_CLASSES[args.model_type]\r\n",
    "    tokenizer = tokenizer_class.from_pretrained(output_dir)\r\n",
    "    model = model_class.from_pretrained(\r\n",
    "        output_dir, num_classes=lable_list_length)\r\n",
    "\r\n",
    "    test_ds = load_dataset('dureader_yesno', splits='test')\r\n",
    "    \r\n",
    "    trans_func = partial(convert_example, tokenizer=tokenizer)\r\n",
    "\r\n",
    "    test_batchify_fn = lambda samples, fn=Dict({\r\n",
    "        'input_ids': Pad(axis=0, pad_val=tokenizer.pad_token_id),\r\n",
    "        'token_type_ids': Pad(axis=0, pad_val=tokenizer.pad_token_type_id),\r\n",
    "        'id': Stack()\r\n",
    "    }): fn(samples)\r\n",
    "\r\n",
    "    test_ds = test_ds.map(trans_func, lazy=True)\r\n",
    "    test_batch_sampler = BatchSampler(\r\n",
    "        dataset=test_ds, \r\n",
    "        batch_size=args.batch_size, \r\n",
    "        shuffle=False\r\n",
    "    )\r\n",
    "    test_data_loader = DataLoader(\r\n",
    "        dataset=test_ds,\r\n",
    "        batch_sampler=test_batch_sampler,\r\n",
    "        collate_fn=test_batchify_fn,\r\n",
    "        return_list=True\r\n",
    "    )\r\n",
    "\r\n",
    "\r\n",
    "    predictions = predict(model, test_data_loader)\r\n",
    "    with open('dureader_yesno.json', \"w\") as writer:\r\n",
    "        writer.write(\r\n",
    "            json.dumps(\r\n",
    "                predictions, ensure_ascii=False, indent=4) + \"\\n\")\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "args = Config(model_type='ernie_gram', \r\n",
    "              model_name_or_path='ernie-gram-zh', \r\n",
    "              output_dir='./checkpoints/dureader-yesno/',\r\n",
    "              \r\n",
    "              max_seq_length=384,\r\n",
    "              batch_size=16, \r\n",
    "              learning_rate=5e-5,\r\n",
    "              num_train_epochs=3,\r\n",
    "              logging_steps=10,\r\n",
    "              save_steps=200,\r\n",
    "              warmup_proportion=0.1,\r\n",
    "              weight_decay=0.01,\r\n",
    "              device='gpu')\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-07-16 09:43:49,519] [    INFO] - Found /home/aistudio/.paddlenlp/models/ernie-gram-zh/vocab.txt\n",
      "[2021-07-16 09:43:54,269] [    INFO] - Already cached /home/aistudio/.paddlenlp/models/ernie-gram-zh/ernie_gram_zh.pdparams\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py:1297: UserWarning: Skip loading for classifier.weight. classifier.weight is not found in the provided dict.\n",
      "  warnings.warn((\"Skip loading for {}. \".format(key) + str(err)))\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py:1297: UserWarning: Skip loading for classifier.bias. classifier.bias is not found in the provided dict.\n",
      "  warnings.warn((\"Skip loading for {}. \".format(key) + str(err)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 10, epoch: 1, batch: 10/4712, loss: 1.087154, speed: 4.79 step/s\n",
      "global step 20, epoch: 1, batch: 20/4712, loss: 1.045500, speed: 5.05 step/s\n",
      "global step 30, epoch: 1, batch: 30/4712, loss: 0.965376, speed: 4.46 step/s\n"
     ]
    }
   ],
   "source": [
    "do_train(args)\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "at global step 13000, best val acc is 0.87166!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "do_predict(args)\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "test acc: 87.64193"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "请点击[此处](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576)查看本环境基本用法.  <br>\n",
    "Please click [here ](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576) for more detailed instructions. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 2.1.0 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
